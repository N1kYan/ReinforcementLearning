% Encoding: UTF-8

@inproceedings{park2005rls,
	title={An RLS-based natural actor-critic algorithm for locomotion of a two-linked robot arm},
	author={Park, Jooyoung and Kim, Jongho and Kang, Daesung},
	booktitle={International Conference on Computational and Information Science},
	pages={65--72},
	year={2005},
	organization={Springer}
}

@inproceedings{peters2007applying,
	title={Applying the Episodic Natural Actor-Critic Architecture to Motor Primitive Learning.},
	author={Peters, Jan and Schaal, Stefan},
	booktitle={ESANN},
	pages={295--300},
	year={2007}
}

@article{kim2010impedance,
	title={Impedance learning for robotic contact tasks using natural actor-critic algorithm},
	author={Kim, Byungchan and Park, Jooyoung and Park, Shinsuk and Kang, Sungchul},
	journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	volume={40},
	number={2},
	pages={433--443},
	year={2010},
	publisher={IEEE}
}

@inproceedings{richter2007natural,
	title={Natural actor-critic for road traffic optimisation},
	author={Richter, Silvia and Aberdeen, Douglas and Yu, Jin},
	booktitle={Advances in neural information processing systems},
	pages={1169--1176},
	year={2007}
}

@article{jurvcivcek2011natural,
	title={Natural actor and belief critic: Reinforcement algorithm for learning parameters of dialogue systems modelled as POMDPs},
	author={Jur{\v{c}}{\'\i}{\v{c}}ek, Filip and Thomson, Blaise and Young, Steve},
	journal={ACM Transactions on Speech and Language Processing (TSLP)},
	volume={7},
	number={3},
	pages={6},
	year={2011},
	publisher={ACM}
}

@inproceedings{thomas2014bias,
	title={Bias in natural actor-critic algorithms},
	author={Thomas, Philip},
	booktitle={International Conference on Machine Learning},
	pages={441--448},
	year={2014}
}

@inproceedings{girgin2008basis,
	title={Basis expansion in natural actor critic methods},
	author={Girgin, Sertan and Preux, Philippe},
	booktitle={European Workshop on Reinforcement Learning},
	pages={110--123},
	year={2008},
	organization={Springer}
}

@inproceedings{morimura2005utilizing,
	title={Utilizing the natural gradient in temporal difference reinforcement learning with eligibility traces},
	author={Morimura, Tetsuro and Uchibe, Eij  // i\kern -.15em ji and Doya, Kenji},
	booktitle={International Symposium on Information Geometry and Its Applications},
	pages={256--263},
	year={2005}
}

@article{lee2013incremental,
	title={Incremental receptive field weighted actor-critic},
	author={Lee, Dong-Hyun and Lee, Ju-Jang},
	journal={IEEE Transactions on Industrial Informatics},
	volume={9},
	number={1},
	pages={62--71},
	year={2013},
	publisher={IEEE}
}

@article{grondman2012survey,
	title={A survey of actor-critic reinforcement learning: Standard and natural policy gradients},
	author={Grondman, Ivo and Busoniu, Lucian and Lopes, Gabriel AD and Babuska, Robert},
	journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	volume={42},
	number={6},
	pages={1291--1307},
	year={2012},
	publisher={IEEE}
}


@inproceedings{melo2008fitted,
	title={Fitted natural actor-critic: A new algorithm for continuous state-action MDPs},
	author={Melo, Francisco S and Lopes, Manuel},
	booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
	pages={66--81},
	year={2008},
	organization={Springer}
}

@article{hoerl1970ridge,
	title={Ridge regression: Biased estimation for nonorthogonal problems},
	author={Hoerl, Arthur E and Kennard, Robert W},
	journal={Technometrics},
	volume={12},
	number={1},
	pages={55--67},
	year={1970},
	publisher={Taylor \& Francis Group}
}

@inproceedings{witsch2011enhancing,
	title={Enhancing the episodic natural actor-critic algorithm by a regularisation term to stabilize learning of control structures},
	author={Witsch, Andreas and Reichle, Roland and Geihs, Kurt and Lange, Sascha and Riedmiller, Martin},
	booktitle={2011 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)},
	pages={156--163},
	year={2011},
	organization={IEEE}
}

@book{boyd2004convex,
	title={Convex optimization},
	author={Boyd, Stephen and Vandenberghe, Lieven},
	year={2004},
	publisher={Cambridge university press}
}

@article{sohl2012natural,
	title={The natural gradient by analogy to signal whitening, and recipes and tricks for its use},
	author={Sohl-Dickstein, Jascha},
	journal={arXiv preprint arXiv:1205.1828},
	year={2012}
}

@article{desjardins2013metric,
	title={Metric-free natural gradient for joint-training of boltzmann machines},
	author={Desjardins, Guillaume and Pascanu, Razvan and Courville, Aaron and Bengio, Yoshua},
	journal={arXiv preprint arXiv:1301.3545},
	year={2013}
}

@article{pascanu2013revisiting,
	title={Revisiting natural gradient for deep networks},
	author={Pascanu, Razvan and Bengio, Yoshua},
	journal={arXiv preprint arXiv:1301.3584},
	year={2013}
}

@article{amari1998natural,
	title={Natural gradient works efficiently in learning},
	author={Amari, Shun-Ichi},
	journal={Neural computation},
	volume={10},
	number={2},
	pages={251--276},
	year={1998},
	publisher={MIT Press}
}

@book{sutton2018reinforcement,
	title={Reinforcement learning: An introduction},
	author={Sutton, Richard S and Barto, Andrew G},
	year={2018},
	publisher={MIT press}
}

@book{bishop2006pattern,
	title={Pattern recognition and machine learning},
	author={Bishop, Christopher M},
	year={2006},
	publisher={springer}
}

@inproceedings{riedmiller2007evaluation,
	title={Evaluation of policy gradient methods and variants on the cart-pole benchmark},
	author={Riedmiller, Martin and Peters, Jan and Schaal, Stefan},
	booktitle={2007 IEEE International Symposium on Approximate Dynamic Programming and Reinforcement Learning},
	pages={254--261},
	year={2007},
	organization={IEEE}
}

% For function approximation
@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{peters2008natural,
	title={Natural actor-critic},
	author={Peters, Jan and Schaal, Stefan},
	journal={Neurocomputing},
	volume={71},
	number={7-9},
	pages={1180--1190},
	year={2008},
	publisher={Elsevier}
}

@inproceedings{peters2005natural,
	title={Natural actor-critic},
	author={Peters, Jan and Vijayakumar, Sethu and Schaal, Stefan},
	booktitle={European Conference on Machine Learning},
	pages={280--291},
	year={2005},
	organization={Springer}
}

@article{peters2008reinforcement,
	title={Reinforcement learning of motor skills with policy gradients},
	author={Peters, Jan and Schaal, Stefan},
	journal={Neural networks},
	volume={21},
	number={4},
	pages={682--697},
	year={2008},
	publisher={Elsevier}
}


@article{dann2014policy,
	title={Policy evaluation with temporal differences: A survey and comparison},
	author={Dann, Christoph and Neumann, Gerhard and Peters, Jan},
	journal={The Journal of Machine Learning Research},
	volume={15},
	number={1},
	pages={809--883},
	year={2014},
	publisher={JMLR. org}
}

@inproceedings{bhatnagar2008incremental,
	title={Incremental natural actor-critic algorithms},
	author={Bhatnagar, Shalabh and Ghavamzadeh, Mohammad and Lee, Mark and Sutton, Richard S},
	booktitle={Advances in neural information processing systems},
	pages={105--112},
	year={2008}
}


@article{bhatnagar2009natural,
	title={Natural actor--critic algorithms},
	author={Bhatnagar, Shalabh and Sutton, Richard S and Ghavamzadeh, Mohammad and Lee, Mark},
	journal={Automatica},
	volume={45},
	number={11},
	pages={2471--2482},
	year={2009},
	publisher={Elsevier}
}