\begin{thebibliography}{27}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{{#1}}
\providecommand{\urlprefix}{URL }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{DOI~\discretionary{}{}{}#1}\else
  \providecommand{\doi}{DOI~\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi
\providecommand{\eprint}[2][]{\url{#2}}

\bibitem[{Barth-Maron et~al.(2018)Barth-Maron, Hoffman, Budden, Dabney, Horgan,
  Muldal, Heess, and Lillicrap}]{barth2018distributed}
Barth-Maron G, Hoffman MW, Budden D, Dabney W, Horgan D, Muldal A, Heess N,
  Lillicrap T (2018) Distributed distributional deterministic policy gradients.
  arXiv preprint arXiv:180408617

\bibitem[{Bellemare et~al.(2017)Bellemare, Dabney, and
  Munos}]{bellemare2017distributional}
Bellemare MG, Dabney W, Munos R (2017) A distributional perspective on
  reinforcement learning. In: Proceedings of the 34th International Conference
  on Machine Learning-Volume 70, JMLR. org, pp 449--458

\bibitem[{Glynn and Iglehart(1989)}]{glynn1989importance}
Glynn PW, Iglehart DL (1989) Importance sampling for stochastic simulations.
  Management Science 35(11):1367--1392

\bibitem[{Haykin(1994)}]{haykin1994neural}
Haykin S (1994) Neural networks, vol~2. Prentice hall New York

\bibitem[{He et~al.(2016)He, Zhang, Ren, and Sun}]{he2016deep}
He K, Zhang X, Ren S, Sun J (2016) Deep residual learning for image
  recognition. In: Proceedings of the IEEE conference on computer vision and
  pattern recognition, pp 770--778

\bibitem[{Howard(1960)}]{howard1960dynamic}
Howard RA (1960) Dynamic programming and markov processes.

\bibitem[{Jaakkola et~al.(1994)Jaakkola, Jordan, and
  Singh}]{jaakkola1994convergence}
Jaakkola T, Jordan MI, Singh SP (1994) Convergence of stochastic iterative
  dynamic programming algorithms. In: Advances in neural information processing
  systems, pp 703--710

\bibitem[{Kingma and Ba(2014)}]{kingma2014adam}
Kingma DP, Ba J (2014) Adam: A method for stochastic optimization. arXiv
  preprint arXiv:14126980

\bibitem[{Konda and Tsitsiklis(2000)}]{konda2000actor}
Konda VR, Tsitsiklis JN (2000) Actor-critic algorithms. In: Advances in neural
  information processing systems, pp 1008--1014

\bibitem[{Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra}]{lillicrap2015continuous}
Lillicrap TP, Hunt JJ, Pritzel A, Heess N, Erez T, Tassa Y, Silver D, Wierstra
  D (2015) Continuous control with deep reinforcement learning. arXiv preprint
  arXiv:150902971

\bibitem[{Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller}]{mnih2013playing}
Mnih V, Kavukcuoglu K, Silver D, Graves A, Antonoglou I, Wierstra D, Riedmiller
  M (2013) Playing atari with deep reinforcement learning. arXiv preprint
  arXiv:13125602

\bibitem[{Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski et~al.}]{mnih2015human}
Mnih V, Kavukcuoglu K, Silver D, Rusu AA, Veness J, Bellemare MG, Graves A,
  Riedmiller M, Fidjeland AK, Ostrovski G, et~al. (2015) Human-level control
  through deep reinforcement learning. Nature 518(7540):529

\bibitem[{Moore and Atkeson(1993)}]{moore1993prioritized}
Moore AW, Atkeson CG (1993) Prioritized sweeping: Reinforcement learning with
  less data and less time. Machine learning 13(1):103--130

\bibitem[{Nowlan and Hinton(1992)}]{nowlan1992simplifying}
Nowlan SJ, Hinton GE (1992) Simplifying neural networks by soft weight-sharing.
  Neural computation 4(4):473--493

\bibitem[{Plappert et~al.(2017)Plappert, Houthooft, Dhariwal, Sidor, Chen,
  Chen, Asfour, Abbeel, and Andrychowicz}]{plappert2017parameter}
Plappert M, Houthooft R, Dhariwal P, Sidor S, Chen RY, Chen X, Asfour T, Abbeel
  P, Andrychowicz M (2017) Parameter space noise for exploration. arXiv
  preprint arXiv:170601905

\bibitem[{Ribeiro and Szepesv{\'a}ri(1996)}]{ribeiro1996q}
Ribeiro C, Szepesv{\'a}ri C (1996) Q-learning combined with spreading:
  Convergence and results. In: Procs. of the ISRF-IEE International Conf. on
  Intelligent and Cognitive Systems (Neural Networks Symposium), pp 32--36

\bibitem[{Ricciardi and Sacerdote(1979)}]{ricciardi1979ornstein}
Ricciardi LM, Sacerdote L (1979) The ornstein-uhlenbeck process as a model for
  neuronal activity. Biological cybernetics 35(1):1--9

\bibitem[{Riedmiller(2005)}]{riedmiller2005neural}
Riedmiller M (2005) Neural fitted q iteration--first experiences with a data
  efficient neural reinforcement learning method. In: European Conference on
  Machine Learning, Springer, pp 317--328

\bibitem[{Salimans et~al.(2017)Salimans, Ho, Chen, Sidor, and
  Sutskever}]{salimans2017evolution}
Salimans T, Ho J, Chen X, Sidor S, Sutskever I (2017) Evolution strategies as a
  scalable alternative to reinforcement learning. arXiv preprint
  arXiv:170303864

\bibitem[{Schaul et~al.(2015)Schaul, Quan, Antonoglou, and
  Silver}]{schaul2015prioritized}
Schaul T, Quan J, Antonoglou I, Silver D (2015) Prioritized experience replay.
  arXiv preprint arXiv:151105952

\bibitem[{Silver et~al.(2014)Silver, Lever, Heess, Degris, Wierstra, and
  Riedmiller}]{silver2014deterministic}
Silver D, Lever G, Heess N, Degris T, Wierstra D, Riedmiller M (2014)
  Deterministic policy gradient algorithms. In: ICML

\bibitem[{Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov}]{srivastava2014dropout}
Srivastava N, Hinton G, Krizhevsky A, Sutskever I, Salakhutdinov R (2014)
  Dropout: a simple way to prevent neural networks from overfitting. The
  Journal of Machine Learning Research 15(1):1929--1958

\bibitem[{Sutton and Barto(2018)}]{sutton2018reinforcement}
Sutton RS, Barto AG (2018) Reinforcement learning: An introduction. MIT press

\bibitem[{Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich}]{szegedy2015going}
Szegedy C, Liu W, Jia Y, Sermanet P, Reed S, Anguelov D, Erhan D, Vanhoucke V,
  Rabinovich A (2015) Going deeper with convolutions. In: Proceedings of the
  IEEE conference on computer vision and pattern recognition, pp 1--9

\bibitem[{Tesauro(1995)}]{tesauro1995temporal}
Tesauro G (1995) Temporal difference learning and td-gammon. Communications of
  the ACM 38(3):58--69

\bibitem[{Watkins and Dayan(1992)}]{watkins1992q}
Watkins CJ, Dayan P (1992) Q-learning. Machine learning 8(3-4):279--292

\bibitem[{Zeiler and Fergus(2013)}]{zeiler2013stochastic}
Zeiler MD, Fergus R (2013) Stochastic pooling for regularization of deep
  convolutional neural networks. arXiv preprint arXiv:13013557

\end{thebibliography}
