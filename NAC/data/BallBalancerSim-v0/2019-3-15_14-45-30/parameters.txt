Environment name: BallBalancerSim-v0
Is Env discrete/continuous: continuous
Do we use continuous actions (or discretize): [3, 3]
Learning Epochs/num of Updates: 500
Batch size: 2000
Discount factor for monte carlo return: 0.99
Network generation time: 631 seconds
Network training time: 1114 seconds
Learning rate actor: 0.001
Learning rate for Adam optimizer in critic: 0.01
Critic hidden layer size: 10