Environment name: BallBalancerSim-v0
Is Env discrete/continuous: continuous
Do we use continuous actions (or discretize): [3, 3]
Learning Epochs/num of Updates: 500
Batch size: 2000
Discount factor for monte carlo return: 0.9
Network generation time: 638 seconds
Network training time: 863 seconds
Learning rate actor: 0.001
Learning rate for Adam optimizer in critic: 0.1
Critic hidden layer size: 10