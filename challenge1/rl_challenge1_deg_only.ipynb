{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import gym\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.]\n",
      "[-1. -1. -8.]\n"
     ]
    }
   ],
   "source": [
    "# Create gym environment\n",
    "env = gym.make('Pendulum-v0')\n",
    "env.reset()\n",
    "#action space is a Box(1,) with values between [-2,2], joint effort\n",
    "print(env.action_space.low)\n",
    "#observation space is 3d angle of pendulum cos, sin, velocity max:1,1,8; min:-1,-1,-8\n",
    "print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.65612121  0.75465552  0.81729291]\n",
      "[0.19525401]\n",
      "[-0.70774137  0.70647162  1.41257266] -5.294751193708466 False {}\n"
     ]
    }
   ],
   "source": [
    "#reward formular: -(theta^2 + 0.1*theta_dt^2 + 0.001*action^2) (-16.27 is worst, 0 best)\n",
    "print(env.reset())\n",
    "a = env.action_space.sample()\n",
    "print(a)\n",
    "state, reward, done, info = env.step(a)\n",
    "# state = [cos, sin, angle-speed]\n",
    "print(state, reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This method transforms cos and sin input to true degree value by arctan2 function\n",
    "    \n",
    "\"\"\"\n",
    "def my_arctan(cos, sin):\n",
    "    return np.rad2deg(np.arctan2(sin, cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-180., -160., -140., -120., -100.,  -80.,  -60.,  -40.,  -20.,\n",
      "          0.,   20.,   40.,   60.,   80.,  100.,  120.,  140.,  160.,\n",
      "        180.]), array([-8., -7., -6., -5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.,\n",
      "        5.,  6.,  7.,  8.]))\n",
      "[-2.   -1.75 -1.5  -1.25 -1.   -0.75 -0.5  -0.25  0.    0.25  0.5   0.75\n",
      "  1.    1.25  1.5   1.75  2.  ]\n"
     ]
    }
   ],
   "source": [
    "from Discretization import Discretization\n",
    "\n",
    "larry = Discretization(\"degree_only\",\"Pendulum\",state_space_size=(18+1, 16+1),action_space_size=17)\n",
    "\n",
    "print(larry.state_space)\n",
    "print(larry.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression...\n",
      "25%...\n",
      "50%...\n",
      "75%...\n",
      "...done\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xl4FFXW+PHvSUjYdyKEHTQoWxJilEVlFARllUFwR1AcVGTwHUZG9HXg1dH5wcggMjPisAi4jIKCgIDIIggoi2EZkEXZIYLsOwZIcn9/3Oqkydoh3emkcj7P0093V1VX3UrBqVvn3rolxhiUUkq5V0iwC6CUUiqwNNArpZTLaaBXSimX00CvlFIup4FeKaVcTgO9Ukq5nAZ6pZRyOQ30SinlchrolVLK5UoEuwAA1apVM/Xr1w92MZRSqkhZv379cWNMRG7LFYpAX79+fRISEoJdDKWUKlJEZL8vy2nqRimlXE4DvVJKuZwGeqWUcrlCkaNXys2uXLlCYmIiSUlJwS6KKqJKlSpF7dq1CQsLu6bfa6BXKsASExMpX7489evXR0SCXRxVxBhjOHHiBImJiTRo0OCa1qGpG6UCLCkpiapVq2qQV9dERKhatWq+rgg10CtVADTIq/zI778f9wT6pLOw+dNgl0IppQod9wT67V/ArKfg9IFgl0SpQqdcuXIB38ann35K48aNueuuuwK+rUCpX78+x48fzzTde98SEhIYPHgwAMuXL+e7775LW2727Nls27Yt7fvw4cNZsmRJ4AueC/c0xiY7+atL54JbDqWKqcmTJ/POO+/4HOiTk5MpUSLrEGSMwRhDSEjg6qI5bT+jjPsWHx8P2EBfrlw52rRpA9hA37VrV5o0aQLAa6+9FoCS5517avSpKfb98sXglkOpImL//v20b9+e6Oho2rdvz4ED9mr4008/pVmzZsTExNC2bVsAtm7dyq233kpsbCzR0dHs3LnzqnW99tprrFq1imeeeYahQ4eSlJTEE088QfPmzWnRogXLli0DYOrUqfTu3Ztu3brRsWPHq9axb98+GjduzMCBA4mLi+PgwYMsWrSI1q1bExcXR+/evTl//jzr1q2jZ8+eAMyZM4fSpUtz+fJlkpKSaNiwIQATJ07klltuISYmhvvvv5+LF21c6NevH0OGDOGuu+7ixRdf5MSJE3Ts2JEWLVrw9NNPY4zJ9HfKuG/Lly+na9eu7Nu3j3fffZe33nqL2NhYvvnmG+bOncvQoUOJjY1l9+7d9OvXj88++wywVwsjRowgLi6O5s2bs2PHDgCOHTtGhw4diIuL4+mnn6ZevXpZXlXkh3tq9KnJ9v3KheCWQ6kcvPrFVrYdOuvXdTapWYER3Zrm+XeDBg3i8ccfp2/fvrz33nsMHjyY2bNn89prr/HVV19Rq1YtTp8+DcC7777L888/z6OPPsrly5dJSUm5al3Dhw/n66+/ZvTo0cTHx/P3v/8dgC1btrBjxw46duzITz/9BMDq1avZvHkzVapUyVSmH3/8kSlTpvDOO+9w/PhxXn/9dZYsWULZsmUZNWoUY8aM4eWXX2bjxo0ArFy5kmbNmvH999+TnJxMy5YtAejZsye/+93vAHjllVeYPHkyv//97wH46aefWLJkCaGhoQwePJjbb7+d4cOHM3/+fCZMmJCpTBn3bfny5YAN3M888wzlypXjhRdeAKB79+507dqVXr16Zfk3r1atGhs2bOCdd95h9OjRTJo0iVdffZV27drx0ksvsXDhwizLkF/uC/SXNdAr5YvVq1cza9YsAPr06cOf/vQnAG677Tb69evHAw88kFZzbt26NW+88QaJiYn07NmTqKioHNe9atWqtMB60003Ua9evbRA36FDhyyDPEC9evVo1aoVAGvWrGHbtm3cdtttAFy+fJnWrVtTokQJbrjhBrZv3866desYMmQIK1asICUlhTvuuAOAH374gVdeeYXTp09z/vx57rnnnrRt9O7dm9DQUABWrFiR9jfo0qULlStXzuNfMW88f8+bb745bburVq3i888/B+Dee+8NSBncE+iNpm5U4XctNe+C4unC9+6777J27Vrmz59PbGwsmzZt4pFHHqFly5bMnz+fe+65h0mTJtGuXbts15VVCsSjbNmyPs0zxtChQwc+/vjjTMvdcccdfPnll4SFhXH33XfTr18/UlJSGD16NGBTNLNnzyYmJoapU6em1cKz2n5Bdn0tWbIkAKGhoSQn28ppTn8rf3FRjt5Toz8f3HIoVUS0adOGTz75BICPPvqI22+/HYDdu3fTsmVLXnvtNapVq8bBgwfZs2cPDRs2ZPDgwXTv3p3NmzfnuO62bdvy0UcfATZVcuDAAW688cY8la9Vq1Z8++237Nq1C4CLFy+mXRW0bduWsWPH0rp1ayIiIjhx4gQ7duygaVN7Ij137hyRkZFcuXIlrRy5lfPLL7/k1KlTeSpj+fLlOXfuXLbffXH77bczY8YMABYtWpTnMvjCRYHeqdFf0Rq9UhldvHiR2rVrp73GjBnDuHHjmDJlCtHR0XzwwQe8/fbbAAwdOpTmzZvTrFkz2rZtS0xMDNOnT6dZs2bExsayY8cOHn/88Ry3N3DgQFJSUmjevDkPPvggU6dOTavN+ioiIoKpU6fy8MMPEx0dTatWrdIaMFu2bMmRI0fSGoujo6OJjo5Oq53/5S9/oWXLlnTo0IGbbrop222MGDGCFStWEBcXx6JFi6hbt26eytitWzc+//xzYmNjWblyJQ899BBvvvkmLVq0YPfu3T6tY8SIESxatIi4uDi+/PJLIiMjKV++fJ7KkRspiMuG3MTHx5t8P3jk69dhxZtw1yvwm6H+KZhSfrB9+3YaN24c7GKoQurSpUuEhoZSokQJVq9ezbPPPsumTZsyLZfVvyMRWW+Mic9tG+7J0WvqRilVBB04cIAHHniA1NRUwsPDmThxot+34b5Ar6kbpVQREhUVldZdNFDcl6PX7pVKKXUVFwV67UevlFJZ8SnQi0glEflMRHaIyHYRaS0iVURksYjsdN4rO8uKiIwTkV0isllE4gK7Cw5N3SilVJZ8rdG/DSw0xtwExADbgWHAUmNMFLDU+Q7QCYhyXgOA8X4tcXa0Rq+UUlnKNdCLSAWgLTAZwBhz2RhzGrgPmOYsNg3o4Xy+D3jfWGuASiIS6feSZ6Q5eqWyVZSHKR47dmzaoGT+WM7bjh07iI2NTev37hmFct++ffznP/9JW27Tpk0sWLAg7fvcuXMZOXJknrYVTL7U6BsCx4ApIrJRRCaJSFmgujHmMIDzfp2zfC3goNfvE51pVxGRASKSICIJx44dy9dOAFqjVyrIPEP5ekaqzI1nCIDcBDLQz549m/vuu4+NGzdy/fXXp40tn1ug7969O8OGDcu0vsLKl0BfAogDxhtjWgAXSE/TZCWrgSMy3ZVljJlgjIk3xsRHRET4VNgcaY5eqTwpbMMUX7hwgS5duhATE0OzZs2YPn0648aN49ChQ9x1111pVwrPPvss8fHxNG3alBEjRgBkuVxWQxx7W7BgAWPHjmXSpElpv/Fc+QwbNoyVK1cSGxvLqFGjGD58ONOnTyc2Npbp06czdepUBg0aBNhxdQYPHkybNm1o2LBh2rDEqampDBw4kKZNm9K1a1c6d+6cNq+g+dKPPhFINMasdb5/hg30R0Qk0hhz2EnNHPVavo7X72sDh/xV4GxpjV4VBV8Og1+2+HedNZpDp7ynEQrbMMULFy6kZs2azJ8/H4AzZ85QsWJFxowZw7Jly6hWrRoAb7zxBlWqVCElJYX27duzefNmBg8efNVy2Q1xPHz48LTtde7cOdMwwx4jR45k9OjRzJs3D4Dq1auTkJDAP//5T8CesLwdPnyYVatWsWPHDrp3706vXr2YNWsW+/btY8uWLRw9epTGjRvz5JNP5vk4+UOuNXpjzC/AQRHxjEjUHtgGzAX6OtP6AnOcz3OBx53eN62AM54UT0Bpjl6pPFm9ejWPPPIIYIcpXrVqFZA+TPHEiRPTAnrr1q3561//yqhRo9i/fz+lS5fOcd2rVq2iT58+gO/DFDdv3pwlS5bw4osvsnLlSipWrJjlumfMmEFcXBwtWrRg69atVz26z8N7iOPY2FimTZvG/v37ffzL5F2PHj0ICQmhSZMmHDlyBLB/g969exMSEkKNGjWC+ohFX++M/T3wkYiEA3uAJ7AniRki0h84APR2ll0AdAZ2ARedZQPPU6NPvQLJl6FEeIFsVqk8uYaad0EJ9jDFjRo1Yv369SxYsICXXnqJjh07XlUDB9i7dy+jR4/m+++/p3LlyvTr14+kpKQst5/dEMeB4D1gm2ffC8M4Yh4+da80xmxy8unRxpgexphTxpgTxpj2xpgo5/2ks6wxxjxnjLneGNPcGJPP0cp8lOrVsKNPmVIqV4VtmOJDhw5RpkwZHnvsMV544QU2bNgAXD3079mzZylbtiwVK1bkyJEjfPnll2m/914upyGOfeGv4YdnzpxJamoqR44cuWpM/ILmvrFuwD58pHRgnxSjVFHiGabYY8iQIYwbN44nn3ySN998k4iICKZMmQLYYYp37tyJMYb27dsTExPDyJEj+fDDDwkLC6NGjRqZatoZDRw4kGeeeYbmzZtTokQJn4Yp3rJlC0OHDiUkJISwsDDGj7e34AwYMIBOnToRGRnJsmXLaNGiBU2bNqVhw4ZpT5/KajnPEMeXLl0C4PXXX6dRo0Y+/b2io6MpUaIEMTEx9OvXj759+zJy5EhiY2N56aWXfFrH/fffz9KlS2nWrBmNGjWiZcuW2aajAs09wxRP7Qr7VtrPgxKgWs6POlOqoOgwxcXX+fPnKVeuHCdOnODWW2/l22+/pUaNGte0Lh2mGDLU6HWoYqVU8HXt2pXTp09z+fJl/vznP19zkM8vdwX6kBL2XZ8bq5QqBIKZl/fmrtErS1awn7WLpSpkCkOKVBVd+f33465AX8oJ9NrrRhUipUqV4sSJExrs1TUxxnDixAlKlSp1zetwUeomBUo5Ldpao1eFSO3atUlMTMQvYzqpYqlUqVJX9ZrKKxcF+mQoU9V+1hy9KkTCwsJo0KBBsIuhijGXpW6cGr2mbpRSKo27An14OUA0daOUUl5cFOhTILQEhJfV1I1SSnlxUaB3+tGHl9UbppRSyov7An1YGX34iFJKeXFXoJdQm6fX1I1SSqVxUaBPcVI3ZTR1o5RSXlwU6JMhJFRTN0oplYHLAr2nMVa7VyqllIc7Ar0xGuiVUiobLgn0qfZde90opVQm7gj0noeOhIRqjV4ppTJwWaB3UjdXLkJqanDLpJRShYRPgV5E9onIFhHZJCIJzrQqIrJYRHY675Wd6SIi40Rkl4hsFpG4QO4AkDnQg6ZvlFLKkZca/V3GmFivB9EOA5YaY6KApc53gE5AlPMaAIz3V2GzlZpi3z05etBAr5RSjvykbu4DpjmfpwE9vKa/b6w1QCURiczHdnKXMUcPmqdXSimHr4HeAItEZL2IDHCmVTfGHAZw3q9zptcCDnr9NtGZFjhZpW400CulFOD7E6ZuM8YcEpHrgMUisiOHZSWLaZkelumcMAYA1K1b18diZMM70Idpjl4ppbz5VKM3xhxy3o8CnwO3Akc8KRnn/aizeCJQx+vntYFDWaxzgjEm3hgTHxERce17ANnU6HW8G6WUAh8CvYiUFZHyns9AR+AHYC7Q11msLzDH+TwXeNzpfdMKOONJ8QSMd2NsuNMYqyNYKqUU4FvqpjrwuYh4lv+PMWahiHwPzBCR/sABoLez/AKgM7ALuAg84fdSZ+TdGKupG6WUukqugd4YsweIyWL6CaB9FtMN8JxfSucrTd0opVS2XHhnrKZulFLKm0sCvfcNU9q9UimlvLkk0Hvl6ENLQGhJuKKBXimlwHWB3mlyCC+jNXqllHK4NNDrA8KVUsrDnYE+rIymbpRSyuGSQO/1hCnQh48opZQXlwR6r8ZYcAK9pm6UUgpcF+i9Ujd6w5RSSgFuDfSexwkqpZRyS6D3umEKnO6VGuiVUgpcE+gz5ujLaWOsUko5XBboM3SvNJmed6KUUsWOOwN9eBk7LeVy8MqklFKFhEsDfTn7rukbpZRyS6D3NMY6OfowZ6hi7XmjlFJuCfRZdK8ErdErpRRuDfRlnYeNnz4YnPIopVQh4s5AX+tmkFA4sDp4ZVJKqULCJYE+ww1TJctBZLQGeqWUwjWBPhkQCPHanbptIDEBki8FrVhKKVUY+BzoRSRURDaKyDznewMRWSsiO0VkuoiEO9NLOt93OfPrB6boXlKT02vzHvVaQ8olOLQx4JtXSqnCLC81+ueB7V7fRwFvGWOigFNAf2d6f+CUMeYG4C1nucDKKtDXbW3f938X8M0rpVRh5lOgF5HaQBdgkvNdgHbAZ84i04Aezuf7nO8489s7ywdOakrmQF+2GlRrBAfWBHTTSilV2Plaox8L/AlwHuVEVeC0Mcbp7kIiUMv5XAs4CODMP+MsHzipyek3S3mr2xoOrkl/ApVSShVDuQZ6EekKHDXGrPeenMWixod53usdICIJIpJw7NgxnwqbraxSNwD12kDSGTi6LX/rV0qpIsyXGv1tQHcR2Qd8gk3ZjAUqiYgnutYGDjmfE4E6AM78isDJjCs1xkwwxsQbY+IjIiLytRPZBnpPnl67WSqlirFcA70x5iVjTG1jTH3gIeBrY8yjwDKgl7NYX2CO83mu8x1n/tfGBHi84Kxy9ACV6kL5mtogq5Qq1vLTj/5FYIiI7MLm4Cc70ycDVZ3pQ4Bh+SuiD7LL0YvYbpYHVuvY9EqpYiuLanD2jDHLgeXO5z3ArVkskwT09kPZfJdd6gZs+uaHmXBqH1RpUKDFUkqpwsA9d8ZmF+hrxdn3I1sLrjxKKVWIuD/QV6xr38/+XHDlUUqpQsQlgT4l6xw92BunQkvCmcSCLZNSShUSLgn0OdToRaBCTa3RK6WKLfcHeoCKtbVGr5QqtopRoNcavVKqeHJJoM8hRw9QoRacO5z+gBKllCpGXBLoc6vR1wKTAud+KbgyKaVUIVFMAn0d+655eqVUMVQ8An0FZwTlsxrolVLFj0sCfS45+opOoNcGWaVUMeSSQJ9Ljb5URQgvr33plVLFUvEI9JB7X3rtkaOUcikXBfocUjdg0zfZBfoTu+HvN8KGD/xfNqWUCjKXBPpsHjzirUKtrFM3l87DJ4/ChWNw+L+BKZ9SSgWRSwK9LzX62jaYX0lKn2YMzBkIx3+EkhXtTVVKKeUyLgr0PuTo4epa/bdjYdscuPtVqH0znD2U9W+VUqoIKz6BPq0vvRPozyTC0teg6W+hze+hfKTeOauUciWXBHofcvSeGr2nL/32L8CkQrs/26GMy0fC+SPa+0Yp5TouCfQ+5Ogr1LTvnp432+bAdU2h6vXO/Eg7Hs75o4Erp1JKBYGLAn0uNfqw0lCmmh0G4dwROLAGmnRPn1/eORGc0zy9Uspdcg30IlJKRNaJyH9FZKuIvOpMbyAia0Vkp4hMF5FwZ3pJ5/suZ379wO4CvgV6cPrS/ww7vgAMNPYK9BUi7ftZ7XmjlHIXX2r0l4B2xpgYIBa4V0RaAaOAt4wxUcApoL+zfH/glDHmBuAtZ7nASU0FjG+BvkJt2xi7bS5UvQGua5w+r7wT6LWLpVLKZXIN9MY673wNc14GaAd85kyfBvRwPt/nfMeZ315ExG8lzig12b7nlqMH2yB7ci/sW2Vr897FKhsBEqqBXinlOj7l6EUkVEQ2AUeBxcBu4LQxxomyJAJO/0VqAQcBnPlngKr+LPRV0gK9j6mb5F9to6t3fh7siaJ8DU3dKKVcx6dAb4xJMcbEArWBW4HGWS3mvGdVezcZJ4jIABFJEJGEY8eO+VrezPIS6D196SvVhcjYzPPLR2pjrFLKdfLU68YYcxpYDrQCKomIJ7rWBjwRMhGoA+DMrwiczGJdE4wx8caY+IiIiGsrPeSxRu/0pc+YtvHQGr1SyoV86XUTISKVnM+lgbuB7cAyoJezWF9gjvN5rvMdZ/7XxphMNXq/8dzg5EugrxENze6HW/pnPb9CTb07VinlOj5ERyKBaSISij0xzDDGzBORbcAnIvI6sBGY7Cw/GfhARHZha/IPBaDc6fLSGBteBnq9l/388pFw6QxcvgDhZf1TPqWUCrJcA70xZjPQIovpe7D5+ozTk4DefimdL/KSusmN5+7Zs4eh2g35X59SShUCRf/OWJOH1E1u0vrSa4OsUso9in6gz0uOPjfl9e5YpZT7uCDQ5yFHn5sKenesUsp9XBTo/VCjL1kewstroFdKuYoG+owqROqTppRSrqKBPqPyNbRGr5RyFRcEek9jrB9y9GDHpdfGWKWUi7gg0AcgdXP+F2f4Y6WUKvo00GdUvqZd58Xj/lmfUkoFmQb6jNKeNKUNskopd3BBoPfjDVOgT5pSSrmOCwK9H2+YAq+7Y7VGr5RyBxcFej/V6MtVBwmBvSsg6Yx/1qmUUkGkgT6j0BIQ/RBsmw1jmsLCl+GCNswqpYouFwR6P+foAX47HgYshxs7wbp/w7w/+G/dSilVwPwYHYPE3zl6j5ot4P6Jdvyb/34CyZegREn/bkMppQqAC2r0fk7dZBTVEa5cgP3fBmb9SikVYBroc9OgLYSWhJ2LA7N+pZQKMA30uQkvAw3ugJ2LArN+pZQKMBcE+gA0xmYU1RFO7IITuwO3DaWUChAXBPoANcZ6i+po3zV9o5QqglwU6ANYo6/SAKpGwc6vArcNpZQKkFwDvYjUEZFlIrJdRLaKyPPO9CoislhEdjrvlZ3pIiLjRGSXiGwWkbiA7kFBBHqARvfAvlVw+UJgt6OUUn7mS40+GfijMaYx0Ap4TkSaAMOApcaYKGCp8x2gExDlvAYA4/1eam8FkaMHiOoAKZft0AhKKVWE5BrojTGHjTEbnM/ngO1ALeA+YJqz2DSgh/P5PuB9Y60BKolIpN9L7uGp0UuAs1B120B4OfhpYWC3o5RSfpan6Cgi9YEWwFqgujHmMNiTAXCds1gt4KDXzxKdaRnXNUBEEkQk4dixY3kvuUdqsq3Ni1z7OnxRIhxu6gJbZkLS2cBuSyml/MjnQC8i5YCZwP8YY3KKdFlFXJNpgjETjDHxxpj4iIgIX4uRmSfQF4SWz8Dlc7Dxg4LZnlJK+YFPgV5EwrBB/iNjzCxn8hFPSsZ5P+pMTwTqeP28NhC4wd1TUwou0NeKg7qtYe276W0DSilVyPnS60aAycB2Y8wYr1lzgb7O577AHK/pjzu9b1oBZzwpnoBITQ5sH/qMWg2E0wdgx7yC26ZSSuWDLzX624A+QDsR2eS8OgMjgQ4ishPo4HwHWADsAXYBE4GB/i+2l4JM3YDN01eqB6vfKbhtKqVUPuQaIY0xq8g67w7QPovlDfBcPsvlu4IO9CGh0OpZWDgMEtdD7ZsLbttKKXUN3HFnbEEGeoAWj0HJCrDmX77/5kwifPu25vaVUgXOBYE+pWBz9GAfRtKiD2ybA+d+8e03y0fC4uGw8cOrp6dcgd3L9ASglAoYFwT6INToAW7pb7e9fmruyyadgR9mAgJLX4VfT6fPW/QKfNADVo3J9udKKZUfGuivVdXr4Ya7IWGKrZXnZPMMuHIRur0NF0/CN6Ps9G1zbFfNMtVg+Sg4sjXw5VZKFTsa6PPjlt/B+V9y7mppjD0ZRMbAzX3h5n6w9t/w40KYMwhqxsEzq6B0Jfj8mdxPGkoplUcuCPRByNF7RHWwXS3XTcx+mcTv4ehWiH/Sfm/3ZyhZDj5+0A7b0HsqVIiErm/BL5thpaZwlFL+5YJAH8QafUiozdXv/zb7tEvCFAgvD8162e9lq0L74XYQth7joXI9O71xN2jeG1b8zZ44ki8XzD4opVxPA31+tegDJUrZdExGv56CrbMguretxXvc8hQM3W1vvvLW6W9QpxUseAH+dQv8dzqkpga2/Eop19NAn19lqkDsI7BhGqydkD495Qos+jMkJ8HNT2T9u6ym9ZsHj35mu3B+PgBWjg5c2ZVSxUIQI6SfFOSgZtm5dyScPwpfDoUrFyDmEfi0Hxz4DtoMhsho39clYnP/17eHmf3hm7/BjZ2hRrOAFV8p5W4uqdEHqTHWo0RJ26jarBcs+T/45y1waCP0nAQd/3Jt6wwJgc6jbW+cOQO1N45S6pq5JNAXgguT0DDoOcHm3yvUhKcW29x8fpStCl3GwOH/wrdj/VNOpVSxUwgiZD6lJoMEuUbvERIKXf7u33U26Q5Ne9obqirVtw244WXsvIsnYf93UKN5eu8dpZTKwAWBvhDk6AOt85tweBPMegrCytoc/vmjcHANmFQoVQkemwm144NdUqVUIeSS1E0hqdEHStlqMCgB+n5h00H7v7OPNLzjj/DIDJvHn9Yd9iwPdkmVUoVQ0a8KF5YcfaCFhEKDtvbV7e2r50XGwAe/hY96w73/D2IfhbDSwSmnUqrQKfoRsrgE+pyUrwH95sP0x2D+H+HrN+y4OnVawYVj9lWjuU35KKWKnaIfIYtDjt4XZarYYL9vlR0R89u3wbyVPr9kRRi603YFVUoVK0U/QhaHHL2vRKDBHfZ15mc4ewjKRcAvP8D0R2HXkszDLiilXM8lgb7o74bfVaxlXwAVakGZqrDlMw30ShVDLul1o4E+R6Fh0KQH/PglXDof7NIopQpYroFeRN4TkaMi8oPXtCoislhEdjrvlZ3pIiLjRGSXiGwWkbhAFh7QHL2vmveC5F/hp4XBLolSqoD5UqOfCtybYdowYKkxJgpY6nwH6AREOa8BwHj/FDMHmqP3TZ1WNoWz5bNgl0QpVcByDfTGmBXAyQyT7wOmOZ+nAT28pr9vrDVAJRGJ9Fdhs6Q1et+EhEDT39oG2YsZD2cOTuyGhS/bsfWzc+k8vH+f8wB0pVRhc605+urGmMMAzvt1zvRawEGv5RKdaYGjOXrfNe8FqVdg+xd2NMxDG2HnYrhwIuvlj++EKZ1hzb9gwZ+yX+/2L+xdubOetnftKqUKFX9HSMlimslyQZEB2PQOdevWvbatGQNGa/Q+i4yFKtfD4uGwcBhcuZg+r1ojqNcCZvhaAAAQUElEQVQGbupm7749tRemdbNj6bR4DDZ+aAdYa9wt83o3fwIV69o++p88Ck8tgarXF9x+KaVydK0R8oiIRBpjDjupmaPO9ESgjtdytYFDWa3AGDMBmAAQHx+f5ckgV6kp9l0DvW9E7Pg466dCrZuhzi1QNsI+wPzAWpu/Xz8VSlW0z7QNCYO+82zQ/mULfPE/ULe1HXvH4+wh2PMN/OZPEP0gTGoP/3nQPuy8ZHkILwtnEuHID3B0O9zUFW7qHKy/gFLF0rVGyLlAX2Ck8z7Ha/ogEfkEaAmc8aR4AiI12b5rY6zvWjxqX94atLXvV5JgzzLYNheO/wg93oWIRnZej3dhwm9g3h/ggfftSQNg8wzA2CBf9Xp46D82Xz+ta+Zth5SAg2vhxk7pv1dKBVyugV5EPgbuBKqJSCIwAhvgZ4hIf+AA4HnCxgKgM7ALuAhk8bBUP0oL9Fqj94uwUjYI39gp87zqTeDOl2Dpq5DwHtzS36bONk+H2rekp2rqtYHfb4CTu20j7eULUL46VG8GO+bBF8/bIZdrtijYfVOqGMs1QhpjHs5mVvssljXAc/ktlM800Bes2563ja0LhtrAXroKHN2W+WErlerYV0aNu8P8F2yKSAO9UgWmaN8Zqzn6ghUSCr3esw23Mx6Hb0bZPH7Tnr79vkwVO4LmDzPTj51SKuCKeKDXHH2BK1UBHvnEnlx3zING99gA7qvmveHcYdj/bdbzt3wG84bAwe9taigrR7bCmvF6slDKR0W7Kqypm+CoXN82un7aD24dkLffNroXwsvBlk/TG4E99q6Ez5+2xzVhMlzXxHbtbPpb+8D11BT47h+w7A1IuQwlK2RuWFZKZVK0I6QG+uCp2wqGbM9775nwMraL5bY50Hl0+vj4J/fCjD62n3+fz2HXYlg/Db56Gb76X9vIm3IFEtfZvvxnfoav/wJNe9gunEqpbLkkdaOBPiiutYtk896QdMYOxwCQdBY+ftimah7+2A6vfHM/GLDMPiv3zpfg4gk4sct283zgA/vIxHOHYfW/0tebmgqHNmVO+Zw7Yte/Y4HvZfzlB/h5Q/bpI6WKkKIdIdMaYzVHX6Q0/A2UqQbT+9hj5zmOfWZlvqO2WhTc+aJ9GZN+cqnbyvbiWTUW4h638z5/GvZ+Y9NJnf5ml73yK3zyCPycYEfu7PJ3iH8y+7JdOg9L/g++n2i/RzSGuD72BrOLJ+HXkzZ1Vf/2vO/3nuWw9t9w18v20Y4F6dR+2P21LXvEjVA+Uu9lKEaKeKDXGn2RFBoGv/037FtB2qgZDe6Ahnfm/LuMgenu/7Nj7M98ynbzvPIr3NgZ1k2w/yY6vgFzBtkg33OibReY9wdbw79zWOb17fkG5g6C0weh5bM2IG78wKaPMop5xF5VlK6U+/6mJNseSiveBIzdzv2Tcr5D2Bi4fB4unYNy1fNXmTn2E0ztAheOpk+LuAmeWgoly137egPl5B4494tN1ym/KNoRUgN90RV1t33lR9Xr4dbfwZp3oHpz6DXZdv1c+JKddmANHNoA7UdA9AO2UfeL5+GbkXZAt85/szXcK0mw9DU7eFvVG+DJhfaKASD+CTt0w5mfbe+i0pVh00ewcoy9i7j7PzPvx6l9sPlT++9TxAb2A99B7GNwxxCY2d9eZXR4FdoMvvqEc+4X+KAnHNthx3ECO45Q/BP2ysV7+AlfnNhtxyzCwJOLIDnJtnN8/Tps+g+0zGNjen6kptgTc+lKma+Iki/ZdpsN78O+lXbab160aTu98sg3MYUgBxkfH28SEhLy/sOfN8DEu+Dh6XBjxiHzVbFw+SL8uMA28IaVstOMgQUvwPeTIOZh6DE+PVgYY08CX79hA2nr5+DHhXB0K9zyO+jwmm0wzs3PG2D2QDi23Qbr9sPtlcrOJTDzSdsG4VGyAnR+E2IeSi/z7Gdh22xo92do+4KdnpoKH/a0J6hWz9qTSomSdnTQfSshNBxaD4J2r6TX8FOSYfU/bE+mW566Oiie3ANTu9rg3m8+XNc4fd6ku+HCcfj9+quvFoyxJ5kd82x7R+wj9iopY7A1xo5zdGofRMbkfGVw6Rxs/Mj+3U/vt/dePDbTpvDApss+6m1PhpXq2VTZyb32hBr7GHQba/+22THGdtetGmXvwi5GRGS9MSY+t+WKdlVYb5hS4WXs8MveRKDTm9Dsfjs8g3eQErHBvUkP+OolWPl3O7DbI59Co46+b7dWHAxYDov+F74bZ4Nzw9/AitFQvSkM+MYGLY8Qr34P4WWg1xT4PNz2HKpUD6J72yuKPcug29u2Mdqj5dNwdAesegtWjbFXKb2m2OElZj4FB9fY5Y79CJ1G2cC9a4mdB9D3i6uDPNgTxqd97UnSMyLpz+th1gDb6A22HWXHPKh3uz25XDprA+qBNXBkG1w+Z5erVA/un2wHyQMbeBMTbM+pvSvs59QrUKelPSGuGA3TH4MnFtheVh8/ZPehx3iIfsj+rYyBinXs1dfZn22qL7sgvvjPttst2DaV+rfZq6nzR+0Jt/WgYj+QXtGu0e9fDVPuhT6z4fq7/F8w5X6J6236pmzVa1/HD7Ng7mAb+Jr1gu7jfOvymXzJpmkS10HH12030hvvtb2KsktXbHgf5v/R5u0vnbMBrcsYOzrod+PslU31ZrZNoHpTOwBdVkNGpyTDP1pA+ZrQ/ys7wujEdhBaEu74AzTqZNNEG6bBsv8HF4/b34WE2ZNcjWjbhlG6Mix51QbjO4fZEUvXT7VXBRJih8Zu0NaeTGo7Fc8ziTCpgx0Cu1qUPXn8doI92WXa3w/s/oaVtiex6Aev/tusGgtLRtj7LapG2cb4g+vs8uWq23aOM4n2xNike+7HxNuvp+zfqVxE3n5XgHyt0RftQL93pR0lse8825inVLCc3GuHcm7cLW855V9PweSOcPwnG3Sf/Tb3O41/Xg8z+tpAfP/k9EC+Zrxtn8DYmnHXt3JOQ60Zb59L0PcLe5I5uReeWpy59p90xo5oWrke1IrPvM5fT8P8IelPGKt1s70iadw9+8bqI9vgvXvtVUKP8RCb3ZBa2AfgzHnOjnza8C5o3NWW4/Am2+bStKf9O4Rk0Vs86Sx8eH/6VZCvwX77F/bkLSH2b1KlYeZljLEN/Pu/s2m5Oi2zPvZnEm1loFJde5KsWMdv7Q7FI9DvXgYf9IAnFkK91v4vmFIF4dQ+O9b/ncPSG4Fzk+I8KzljwNi5BJJO27RVbsHk0jkY0xRSLtk7jR+enrf0lTdPnrxURd+7jh7ZCheO5d7bCmyadt0E2wju3Xvo+na23CXCs/+td7CP6mjLWLK8bSu5cNSmeMpG2BhSpyVs+hg2fWjbHk4ftFct/RdffdV37Ed7pbFvpU0dpybbk0/Lp+3VTuX6NrW2agysm2j/xh5lI2xKsc6tUPtWO8CfL+1CWSgegX7nEvjofui/JD0/qJTy3eLh8O3btitqm0HBLk3ujLENuokJtjG5xWO+dRFNOmu71h7dbk9wl85CWBmblikbYXtVHdtul5UQuH2IPfH+vAHe726Dd5/PbZpty2f2OQzhZWwX3+a94b+f2Jv3Tu11Nii2ATk12XbFvWOIPQH/vMFekR1cZ4fyBrjnr7bd6BoUj0D/40L4+EH43TJ7SaSUypvkSzYlUv8O7cZ44YRtFK5YByKj06dvm2tHaw0NtzXzkhVsB4A7X746f5+aYtNJJ/bYHk9JZ2yX2Otuyn57id/bZz1UurbHqRaTXjfaj16pfClRMvPgcsVV2apwU5fM05t0h+7/sHcWN+0BUfekd+X1FhJq2ydq3ez79gqoW3jRjpAa6JVSBSGuj30VUTqomVJKuVwRD/Q6qJlSSuWmiAd6rdErpVRuNNArpZTLBSTQi8i9IvKjiOwSkWGB2AaggV4ppXzg90AvIqHAv4BOQBPgYRFp4u/tADqomVJK+SAQNfpbgV3GmD3GmMvAJ8B9AdiOV41eG2OVUio7gagK1wIOen1PBFoGYDv8d/9xYoAu/1pNkpT2+XdS3O8AVEoVGs+3j6JbTM2AbiMQgT6rKJppnAURGQAMAKhb99pu/zVVr2dDud9wQ/XKJIfmMKhRjiVRSqngqVg6h4eq+EkgAn0iUMfre23gUMaFjDETgAlgx7q5lg3FdngUOjyKjnKjlFLZC0SO/nsgSkQaiEg48BAwNwDbUUop5QO/1+iNMckiMgj4CggF3jPGbPX3dpRSSvkmIP0SjTELgAWBWLdSSqm8Kdp3xiqllMqVBnqllHI5DfRKKeVyGuiVUsrlNNArpZTLFYqHg4vIMWD/Nf68GnDcj8UpKorjfhfHfYbiud/FcZ8h7/tdzxgTkdtChSLQ54eIJPjyFHS3KY77XRz3GYrnfhfHfYbA7bembpRSyuU00CullMu5IdBPCHYBgqQ47ndx3GconvtdHPcZArTfRT5Hr5RSKmduqNErpZTKQZEO9AX2EPIgEpE6IrJMRLaLyFYRed6ZXkVEFovITue9crDL6m8iEioiG0VknvO9gYisdfZ5ujMMtquISCUR+UxEdjjHvHUxOdZ/cP59/yAiH4tIKbcdbxF5T0SOisgPXtOyPLZijXNi22YRyddjN4psoC/Qh5AHVzLwR2NMY6AV8Jyzn8OApcaYKGCp891tnge2e30fBbzl7PMpoH9QShVYbwMLjTE3ATHY/Xf1sRaRWsBgIN4Y0ww7vPlDuO94TwXuzTAtu2PbCYhyXgOA8fnZcJEN9BTkQ8iDyBhz2Bizwfl8DvsfvxZ2X6c5i00DegSnhIEhIrWBLsAk57sA7YDPnEXcuM8VgLbAZABjzGVjzGlcfqwdJYDSIlICKAMcxmXH2xizAjiZYXJ2x/Y+4H1jrQEqiUjktW67KAf6rB5CXitIZSkQIlIfaAGsBaobYw6DPRkA1wWvZAExFvgTkOp8rwqcNsYkO9/deLwbAseAKU7KapKIlMXlx9oY8zMwGjiADfBngPW4/3hD9sfWr/GtKAd6nx5C7hYiUg6YCfyPMeZssMsTSCLSFThqjFnvPTmLRd12vEsAccB4Y0wL4AIuS9NkxclL3wc0AGoCZbGpi4zcdrxz4td/70U50Pv0EHI3EJEwbJD/yBgzy5l8xHMp57wfDVb5AuA2oLuI7MOm5Npha/iVnEt7cOfxTgQSjTFrne+fYQO/m481wN3AXmPMMWPMFWAW0Ab3H2/I/tj6Nb4V5UBfLB5C7uSmJwPbjTFjvGbNBfo6n/sCcwq6bIFijHnJGFPbGFMfe1y/NsY8CiwDejmLuWqfAYwxvwAHReRGZ1J7YBsuPtaOA0ArESnj/Hv37Lerj7cju2M7F3jc6X3TCjjjSfFcE2NMkX0BnYGfgN3A/wa7PAHax9uxl2ybgU3OqzM2Z70U2Om8Vwl2WQO0/3cC85zPDYF1wC7gU6BksMsXgP2NBRKc4z0bqFwcjjXwKrAD+AH4ACjptuMNfIxtg7iCrbH3z+7YYlM3/3Ji2xZsj6Rr3rbeGauUUi5XlFM3SimlfKCBXimlXE4DvVJKuZwGeqWUcjkN9Eop5XIa6JVSyuU00CullMtpoFdKKZf7/wQkNiUSIf5oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Regression of old state and performed action to new state and observed reward.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Learning episodes / amount of samples for regression\n",
    "epochs = 10000\n",
    "\n",
    "rtx = []\n",
    "rty = []\n",
    "stx = []\n",
    "sty = []\n",
    "plotr = []\n",
    "plots = []\n",
    "\n",
    "regressorReward = RandomForestRegressor(n_estimators=10, min_samples_split=2)\n",
    "regressorState = RandomForestRegressor(n_estimators=10, min_samples_split=2)\n",
    "\n",
    "old_state = env.reset()\n",
    "# Transform from 3 to 2 dim:(cos, sin, angular velocity) -> (angle, angular velocity)\n",
    "old_state = np.array([my_arctan(old_state[0], old_state[1]), old_state[2]])\n",
    "\n",
    "print(\"Regression...\")\n",
    "for i in range(epochs):\n",
    "    \n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    # Transform from 3 to 2 dim:(cos, sin, angular velocity) -> (angle, angular velocity)\n",
    "    next_state = np.array([my_arctan(next_state[0], next_state[1]), next_state[2]])\n",
    "\n",
    "    rtx.append(np.append(old_state ,action))\n",
    "    rty.append(reward)\n",
    "    stx.append(np.append(old_state,action))\n",
    "    sty.append(next_state)\n",
    "    \n",
    "    if i%100==0: # 50 works nicely\n",
    "        \n",
    "        regressorReward.fit(rtx, rty)\n",
    "        fitrtx = regressorReward.predict(rtx)\n",
    "        mse = mean_squared_error(rty, fitrtx)\n",
    "        plotr.append(mse)\n",
    "\n",
    "        \n",
    "        regressorState.fit(stx, sty)\n",
    "        fitstx = regressorState.predict(stx)\n",
    "        mse = mean_squared_error(sty, fitstx)\n",
    "\n",
    "        plots.append(mse)\n",
    "    \n",
    "    old_state = np.copy(next_state)\n",
    "    \n",
    "    if i==int(epochs*0.25):\n",
    "        print(\"25%...\")\n",
    "    if i==int(epochs*0.5):\n",
    "        print(\"50%...\")\n",
    "    if i==int(epochs*0.75):\n",
    "        print(\"75%...\")\n",
    "\n",
    "print(\"...done\")\n",
    "plt.figure(0)\n",
    "plt.plot(plotr, label=\"Loss for reward fitting\")\n",
    "\n",
    "plt.plot(plots, label=\"Loss for state fitting\")\n",
    "plt.legend()\n",
    "print(regressorReward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Value iteration:\n",
      "Loop number 0 ... Delta =  17.27353056906738\n",
      "Loop number 1 ... Delta =  1.4495265038925567\n",
      "Loop number 2 ... Delta =  0.12404846448368545\n",
      "Loop number 3 ... Delta =  0.01240484644836748\n",
      "Loop number 4 ... Delta =  0.0012404846448372808\n",
      "Loop number 5 ... Delta =  0.00012404846448355045\n",
      "\n",
      "... done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Value Iteration\n",
    "   \n",
    "   Inputs:\n",
    "   disc: Discriminator object\n",
    "   theta: Minimal value function difference for convergence\n",
    "   gamma: Update learning rate\n",
    "   \n",
    "\"\"\"\n",
    "\n",
    "# TODO: Good choice of a learning rate (gamma)\n",
    "\n",
    "def value_iteration(disc, theta, gamma):\n",
    "    \n",
    "    print(\"Starting Value iteration:\")\n",
    "\n",
    "    value_function = np.zeros(shape=disc.state_space_size)\n",
    "    policy = np.zeros(shape=disc.state_space_size)\n",
    "    \n",
    "    delta = theta\n",
    "    \n",
    "    while_loop_num = 0\n",
    "    \n",
    "    while delta >= theta:\n",
    "        \n",
    "        delta = 0\n",
    "        \n",
    "        print(\"Loop number {} ... \".format(while_loop_num), end='')\n",
    "        while_loop_num += 1\n",
    "        \n",
    "        \n",
    "        # Iterate over discrete state space\n",
    "        for j, s0 in enumerate(disc.state_space[0]): # degrees\n",
    "            for s1 in disc.state_space[1]: # angular velocity\n",
    "                \n",
    "                # Get (only positive) indexes for (possibly negative) discrete state(s)\n",
    "                index = disc.map_to_index([s0, s1])\n",
    "                # print(index)\n",
    "\n",
    "                v = value_function[index[0], index[1]]\n",
    "\n",
    "                # Iterate over all actions to get action maximizing expected reward\n",
    "                amax = 2\n",
    "                rmax = -100\n",
    "\n",
    "                for a in disc.action_space:\n",
    "                    # Get sufficient state and reward from regressors\n",
    "                    x = np.array([s0, s1, a])\n",
    "                    x = x.reshape(1,-1)\n",
    "                    next_s = regressorState.predict(x).T.reshape(-1,)\n",
    "                    r = regressorReward.predict(x)\n",
    "\n",
    "                    # Discretize sufficient state\n",
    "                    next_index = disc.map_to_index([next_s[0], next_s[1]])\n",
    "\n",
    "                    # Calculate expected reward\n",
    "                    # Deterministic case; we do not need probability distribution\n",
    "                    expected_reward = r + gamma*value_function[next_index[0], next_index[1]]\n",
    "\n",
    "                    if rmax < expected_reward:\n",
    "                        amax = a\n",
    "                        rmax = expected_reward \n",
    "\n",
    "                # Define value function by maximum expected reward per state\n",
    "                value_function[index[0], index[1]] = rmax\n",
    "                # Define policy by action achieving maximum expected reward per state\n",
    "                policy[index[0], index[1]] = amax\n",
    "                # Update delta\n",
    "                delta = max(delta, np.abs(v-value_function[index[0], index[1]]))\n",
    "            \n",
    "            #if s0 == int((disc.state_space_size[0]-1)*0.25):\n",
    "            #    print(\"25%...\")\n",
    "            #if s0 == int((disc.state_space_size[0]-1)*0.5):\n",
    "            #   print(\"50%...\")\n",
    "            #if s0 == int((disc.state_space_size[0]-1)*0.75):\n",
    "            #    print(\"75%...\")    \n",
    "\n",
    "        print(\"Delta = \", delta)\n",
    "                    \n",
    "                    \n",
    "    print()\n",
    "    print(\"... done!\")\n",
    "    return value_function, policy\n",
    "\n",
    "value_function, policy = value_iteration(disc=larry, theta=0.001, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Degree:  -180.0 , Velocity:  -8.0 Action:  -1.75\n",
      "Degree:  -180.0 , Velocity:  -7.0 Action:  0.5\n",
      "Degree:  -180.0 , Velocity:  -6.0 Action:  -1.0\n",
      "Degree:  -180.0 , Velocity:  -5.0 Action:  0.25\n",
      "Degree:  -180.0 , Velocity:  -4.0 Action:  -0.5\n",
      "Degree:  -180.0 , Velocity:  -3.0 Action:  1.5\n",
      "Degree:  -180.0 , Velocity:  -2.0 Action:  0.25\n",
      "Degree:  -180.0 , Velocity:  -1.0 Action:  -0.75\n",
      "Degree:  -180.0 , Velocity:  0.0 Action:  -2.0\n",
      "Degree:  -180.0 , Velocity:  1.0 Action:  -2.0\n",
      "Degree:  -180.0 , Velocity:  2.0 Action:  -2.0\n",
      "Degree:  -180.0 , Velocity:  3.0 Action:  -2.0\n",
      "Degree:  -180.0 , Velocity:  4.0 Action:  -2.0\n",
      "Degree:  -180.0 , Velocity:  5.0 Action:  -2.0\n",
      "Degree:  -180.0 , Velocity:  6.0 Action:  -2.0\n",
      "Degree:  -180.0 , Velocity:  7.0 Action:  -2.0\n",
      "Degree:  -180.0 , Velocity:  8.0 Action:  -2.0\n",
      "\n",
      "Degree:  -160.0 , Velocity:  -8.0 Action:  -0.25\n",
      "Degree:  -160.0 , Velocity:  -7.0 Action:  -1.5\n",
      "Degree:  -160.0 , Velocity:  -6.0 Action:  -1.5\n",
      "Degree:  -160.0 , Velocity:  -5.0 Action:  -1.5\n",
      "Degree:  -160.0 , Velocity:  -4.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  -3.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  -2.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  -1.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  0.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  1.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  2.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  3.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  4.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  5.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  6.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  7.0 Action:  -2.0\n",
      "Degree:  -160.0 , Velocity:  8.0 Action:  -2.0\n",
      "\n",
      "Degree:  -140.0 , Velocity:  -8.0 Action:  0.0\n",
      "Degree:  -140.0 , Velocity:  -7.0 Action:  0.0\n",
      "Degree:  -140.0 , Velocity:  -6.0 Action:  1.5\n",
      "Degree:  -140.0 , Velocity:  -5.0 Action:  1.25\n",
      "Degree:  -140.0 , Velocity:  -4.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  -3.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  -2.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  -1.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  0.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  1.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  2.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  3.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  4.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  5.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  6.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  7.0 Action:  -2.0\n",
      "Degree:  -140.0 , Velocity:  8.0 Action:  -2.0\n",
      "\n",
      "Degree:  -120.0 , Velocity:  -8.0 Action:  0.0\n",
      "Degree:  -120.0 , Velocity:  -7.0 Action:  1.25\n",
      "Degree:  -120.0 , Velocity:  -6.0 Action:  -1.25\n",
      "Degree:  -120.0 , Velocity:  -5.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  -4.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  -3.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  -2.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  -1.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  0.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  1.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  2.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  3.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  4.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  5.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  6.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  7.0 Action:  -2.0\n",
      "Degree:  -120.0 , Velocity:  8.0 Action:  -2.0\n",
      "\n",
      "Degree:  -100.0 , Velocity:  -8.0 Action:  0.0\n",
      "Degree:  -100.0 , Velocity:  -7.0 Action:  0.0\n",
      "Degree:  -100.0 , Velocity:  -6.0 Action:  -2.0\n",
      "Degree:  -100.0 , Velocity:  -5.0 Action:  1.0\n",
      "Degree:  -100.0 , Velocity:  -4.0 Action:  0.25\n",
      "Degree:  -100.0 , Velocity:  -3.0 Action:  1.25\n",
      "Degree:  -100.0 , Velocity:  -2.0 Action:  2.0\n",
      "Degree:  -100.0 , Velocity:  -1.0 Action:  1.25\n",
      "Degree:  -100.0 , Velocity:  0.0 Action:  -1.0\n",
      "Degree:  -100.0 , Velocity:  1.0 Action:  1.25\n",
      "Degree:  -100.0 , Velocity:  2.0 Action:  -0.25\n",
      "Degree:  -100.0 , Velocity:  3.0 Action:  -2.0\n",
      "Degree:  -100.0 , Velocity:  4.0 Action:  1.0\n",
      "Degree:  -100.0 , Velocity:  5.0 Action:  0.5\n",
      "Degree:  -100.0 , Velocity:  6.0 Action:  0.0\n",
      "Degree:  -100.0 , Velocity:  7.0 Action:  -1.0\n",
      "Degree:  -100.0 , Velocity:  8.0 Action:  -1.0\n",
      "\n",
      "Degree:  -80.0 , Velocity:  -8.0 Action:  -2.0\n",
      "Degree:  -80.0 , Velocity:  -7.0 Action:  1.0\n",
      "Degree:  -80.0 , Velocity:  -6.0 Action:  -1.75\n",
      "Degree:  -80.0 , Velocity:  -5.0 Action:  -1.75\n",
      "Degree:  -80.0 , Velocity:  -4.0 Action:  -1.5\n",
      "Degree:  -80.0 , Velocity:  -3.0 Action:  0.0\n",
      "Degree:  -80.0 , Velocity:  -2.0 Action:  0.5\n",
      "Degree:  -80.0 , Velocity:  -1.0 Action:  2.0\n",
      "Degree:  -80.0 , Velocity:  0.0 Action:  -0.75\n",
      "Degree:  -80.0 , Velocity:  1.0 Action:  1.25\n",
      "Degree:  -80.0 , Velocity:  2.0 Action:  -0.5\n",
      "Degree:  -80.0 , Velocity:  3.0 Action:  0.5\n",
      "Degree:  -80.0 , Velocity:  4.0 Action:  -0.75\n",
      "Degree:  -80.0 , Velocity:  5.0 Action:  0.25\n",
      "Degree:  -80.0 , Velocity:  6.0 Action:  1.0\n",
      "Degree:  -80.0 , Velocity:  7.0 Action:  0.0\n",
      "Degree:  -80.0 , Velocity:  8.0 Action:  0.0\n",
      "\n",
      "Degree:  -60.0 , Velocity:  -8.0 Action:  -2.0\n",
      "Degree:  -60.0 , Velocity:  -7.0 Action:  -2.0\n",
      "Degree:  -60.0 , Velocity:  -6.0 Action:  -1.75\n",
      "Degree:  -60.0 , Velocity:  -5.0 Action:  -2.0\n",
      "Degree:  -60.0 , Velocity:  -4.0 Action:  -0.5\n",
      "Degree:  -60.0 , Velocity:  -3.0 Action:  -0.25\n",
      "Degree:  -60.0 , Velocity:  -2.0 Action:  1.5\n",
      "Degree:  -60.0 , Velocity:  -1.0 Action:  -1.25\n",
      "Degree:  -60.0 , Velocity:  0.0 Action:  -1.25\n",
      "Degree:  -60.0 , Velocity:  1.0 Action:  1.75\n",
      "Degree:  -60.0 , Velocity:  2.0 Action:  -1.5\n",
      "Degree:  -60.0 , Velocity:  3.0 Action:  -1.0\n",
      "Degree:  -60.0 , Velocity:  4.0 Action:  -2.0\n",
      "Degree:  -60.0 , Velocity:  5.0 Action:  -0.25\n",
      "Degree:  -60.0 , Velocity:  6.0 Action:  -0.5\n",
      "Degree:  -60.0 , Velocity:  7.0 Action:  -0.5\n",
      "Degree:  -60.0 , Velocity:  8.0 Action:  -0.5\n",
      "\n",
      "Degree:  -40.0 , Velocity:  -8.0 Action:  0.0\n",
      "Degree:  -40.0 , Velocity:  -7.0 Action:  0.0\n",
      "Degree:  -40.0 , Velocity:  -6.0 Action:  0.0\n",
      "Degree:  -40.0 , Velocity:  -5.0 Action:  -2.0\n",
      "Degree:  -40.0 , Velocity:  -4.0 Action:  -1.75\n",
      "Degree:  -40.0 , Velocity:  -3.0 Action:  0.0\n",
      "Degree:  -40.0 , Velocity:  -2.0 Action:  -1.0\n",
      "Degree:  -40.0 , Velocity:  -1.0 Action:  0.75\n",
      "Degree:  -40.0 , Velocity:  0.0 Action:  -0.75\n",
      "Degree:  -40.0 , Velocity:  1.0 Action:  1.25\n",
      "Degree:  -40.0 , Velocity:  2.0 Action:  -2.0\n",
      "Degree:  -40.0 , Velocity:  3.0 Action:  -1.5\n",
      "Degree:  -40.0 , Velocity:  4.0 Action:  -1.75\n",
      "Degree:  -40.0 , Velocity:  5.0 Action:  -1.75\n",
      "Degree:  -40.0 , Velocity:  6.0 Action:  -1.75\n",
      "Degree:  -40.0 , Velocity:  7.0 Action:  -1.75\n",
      "Degree:  -40.0 , Velocity:  8.0 Action:  -1.75\n",
      "\n",
      "Degree:  -20.0 , Velocity:  -8.0 Action:  -2.0\n",
      "Degree:  -20.0 , Velocity:  -7.0 Action:  -2.0\n",
      "Degree:  -20.0 , Velocity:  -6.0 Action:  -1.75\n",
      "Degree:  -20.0 , Velocity:  -5.0 Action:  -2.0\n",
      "Degree:  -20.0 , Velocity:  -4.0 Action:  1.75\n",
      "Degree:  -20.0 , Velocity:  -3.0 Action:  1.75\n",
      "Degree:  -20.0 , Velocity:  -2.0 Action:  0.75\n",
      "Degree:  -20.0 , Velocity:  -1.0 Action:  -2.0\n",
      "Degree:  -20.0 , Velocity:  0.0 Action:  1.25\n",
      "Degree:  -20.0 , Velocity:  1.0 Action:  -2.0\n",
      "Degree:  -20.0 , Velocity:  2.0 Action:  -1.0\n",
      "Degree:  -20.0 , Velocity:  3.0 Action:  -1.25\n",
      "Degree:  -20.0 , Velocity:  4.0 Action:  -1.75\n",
      "Degree:  -20.0 , Velocity:  5.0 Action:  -1.75\n",
      "Degree:  -20.0 , Velocity:  6.0 Action:  -0.5\n",
      "Degree:  -20.0 , Velocity:  7.0 Action:  -0.5\n",
      "Degree:  -20.0 , Velocity:  8.0 Action:  -0.5\n",
      "\n",
      "Degree:  0.0 , Velocity:  -8.0 Action:  1.25\n",
      "Degree:  0.0 , Velocity:  -7.0 Action:  1.25\n",
      "Degree:  0.0 , Velocity:  -6.0 Action:  -1.75\n",
      "Degree:  0.0 , Velocity:  -5.0 Action:  -2.0\n",
      "Degree:  0.0 , Velocity:  -4.0 Action:  1.75\n",
      "Degree:  0.0 , Velocity:  -3.0 Action:  1.75\n",
      "Degree:  0.0 , Velocity:  -2.0 Action:  -2.0\n",
      "Degree:  0.0 , Velocity:  -1.0 Action:  -0.25\n",
      "Degree:  0.0 , Velocity:  0.0 Action:  -0.25\n",
      "Degree:  0.0 , Velocity:  1.0 Action:  0.25\n",
      "Degree:  0.0 , Velocity:  2.0 Action:  -0.5\n",
      "Degree:  0.0 , Velocity:  3.0 Action:  -1.25\n",
      "Degree:  0.0 , Velocity:  4.0 Action:  -1.75\n",
      "Degree:  0.0 , Velocity:  5.0 Action:  -1.75\n",
      "Degree:  0.0 , Velocity:  6.0 Action:  -0.5\n",
      "Degree:  0.0 , Velocity:  7.0 Action:  -0.5\n",
      "Degree:  0.0 , Velocity:  8.0 Action:  -0.5\n",
      "\n",
      "Degree:  20.0 , Velocity:  -8.0 Action:  -2.0\n",
      "Degree:  20.0 , Velocity:  -7.0 Action:  -2.0\n",
      "Degree:  20.0 , Velocity:  -6.0 Action:  -0.25\n",
      "Degree:  20.0 , Velocity:  -5.0 Action:  -2.0\n",
      "Degree:  20.0 , Velocity:  -4.0 Action:  -2.0\n",
      "Degree:  20.0 , Velocity:  -3.0 Action:  1.75\n",
      "Degree:  20.0 , Velocity:  -2.0 Action:  -1.5\n",
      "Degree:  20.0 , Velocity:  -1.0 Action:  -0.25\n",
      "Degree:  20.0 , Velocity:  0.0 Action:  1.0\n",
      "Degree:  20.0 , Velocity:  1.0 Action:  -1.25\n",
      "Degree:  20.0 , Velocity:  2.0 Action:  -1.5\n",
      "Degree:  20.0 , Velocity:  3.0 Action:  -1.25\n",
      "Degree:  20.0 , Velocity:  4.0 Action:  -1.75\n",
      "Degree:  20.0 , Velocity:  5.0 Action:  -1.75\n",
      "Degree:  20.0 , Velocity:  6.0 Action:  -0.5\n",
      "Degree:  20.0 , Velocity:  7.0 Action:  -0.5\n",
      "Degree:  20.0 , Velocity:  8.0 Action:  -0.5\n",
      "\n",
      "Degree:  40.0 , Velocity:  -8.0 Action:  -2.0\n",
      "Degree:  40.0 , Velocity:  -7.0 Action:  -2.0\n",
      "Degree:  40.0 , Velocity:  -6.0 Action:  -0.25\n",
      "Degree:  40.0 , Velocity:  -5.0 Action:  -2.0\n",
      "Degree:  40.0 , Velocity:  -4.0 Action:  -1.25\n",
      "Degree:  40.0 , Velocity:  -3.0 Action:  1.5\n",
      "Degree:  40.0 , Velocity:  -2.0 Action:  1.25\n",
      "Degree:  40.0 , Velocity:  -1.0 Action:  0.75\n",
      "Degree:  40.0 , Velocity:  0.0 Action:  1.25\n",
      "Degree:  40.0 , Velocity:  1.0 Action:  1.25\n",
      "Degree:  40.0 , Velocity:  2.0 Action:  1.0\n",
      "Degree:  40.0 , Velocity:  3.0 Action:  -2.0\n",
      "Degree:  40.0 , Velocity:  4.0 Action:  -0.5\n",
      "Degree:  40.0 , Velocity:  5.0 Action:  -0.5\n",
      "Degree:  40.0 , Velocity:  6.0 Action:  -0.5\n",
      "Degree:  40.0 , Velocity:  7.0 Action:  -0.5\n",
      "Degree:  40.0 , Velocity:  8.0 Action:  -0.5\n",
      "\n",
      "Degree:  60.0 , Velocity:  -8.0 Action:  1.25\n",
      "Degree:  60.0 , Velocity:  -7.0 Action:  1.25\n",
      "Degree:  60.0 , Velocity:  -6.0 Action:  0.0\n",
      "Degree:  60.0 , Velocity:  -5.0 Action:  -0.75\n",
      "Degree:  60.0 , Velocity:  -4.0 Action:  -2.0\n",
      "Degree:  60.0 , Velocity:  -3.0 Action:  -2.0\n",
      "Degree:  60.0 , Velocity:  -2.0 Action:  0.75\n",
      "Degree:  60.0 , Velocity:  -1.0 Action:  0.75\n",
      "Degree:  60.0 , Velocity:  0.0 Action:  0.75\n",
      "Degree:  60.0 , Velocity:  1.0 Action:  0.75\n",
      "Degree:  60.0 , Velocity:  2.0 Action:  -0.5\n",
      "Degree:  60.0 , Velocity:  3.0 Action:  -0.25\n",
      "Degree:  60.0 , Velocity:  4.0 Action:  -1.0\n",
      "Degree:  60.0 , Velocity:  5.0 Action:  -0.25\n",
      "Degree:  60.0 , Velocity:  6.0 Action:  -0.25\n",
      "Degree:  60.0 , Velocity:  7.0 Action:  -0.25\n",
      "Degree:  60.0 , Velocity:  8.0 Action:  -0.25\n",
      "\n",
      "Degree:  80.0 , Velocity:  -8.0 Action:  1.5\n",
      "Degree:  80.0 , Velocity:  -7.0 Action:  1.5\n",
      "Degree:  80.0 , Velocity:  -6.0 Action:  0.5\n",
      "Degree:  80.0 , Velocity:  -5.0 Action:  2.0\n",
      "Degree:  80.0 , Velocity:  -4.0 Action:  1.75\n",
      "Degree:  80.0 , Velocity:  -3.0 Action:  -2.0\n",
      "Degree:  80.0 , Velocity:  -2.0 Action:  -2.0\n",
      "Degree:  80.0 , Velocity:  -1.0 Action:  -0.75\n",
      "Degree:  80.0 , Velocity:  0.0 Action:  -0.75\n",
      "Degree:  80.0 , Velocity:  1.0 Action:  -0.75\n",
      "Degree:  80.0 , Velocity:  2.0 Action:  -2.0\n",
      "Degree:  80.0 , Velocity:  3.0 Action:  0.75\n",
      "Degree:  80.0 , Velocity:  4.0 Action:  -2.0\n",
      "Degree:  80.0 , Velocity:  5.0 Action:  2.0\n",
      "Degree:  80.0 , Velocity:  6.0 Action:  -0.25\n",
      "Degree:  80.0 , Velocity:  7.0 Action:  -0.25\n",
      "Degree:  80.0 , Velocity:  8.0 Action:  -0.25\n",
      "\n",
      "Degree:  100.0 , Velocity:  -8.0 Action:  -2.0\n",
      "Degree:  100.0 , Velocity:  -7.0 Action:  -2.0\n",
      "Degree:  100.0 , Velocity:  -6.0 Action:  -2.0\n",
      "Degree:  100.0 , Velocity:  -5.0 Action:  -2.0\n",
      "Degree:  100.0 , Velocity:  -4.0 Action:  -1.25\n",
      "Degree:  100.0 , Velocity:  -3.0 Action:  0.5\n",
      "Degree:  100.0 , Velocity:  -2.0 Action:  -2.0\n",
      "Degree:  100.0 , Velocity:  -1.0 Action:  -0.75\n",
      "Degree:  100.0 , Velocity:  0.0 Action:  -0.75\n",
      "Degree:  100.0 , Velocity:  1.0 Action:  1.5\n",
      "Degree:  100.0 , Velocity:  2.0 Action:  -0.75\n",
      "Degree:  100.0 , Velocity:  3.0 Action:  -1.25\n",
      "Degree:  100.0 , Velocity:  4.0 Action:  -2.0\n",
      "Degree:  100.0 , Velocity:  5.0 Action:  1.75\n",
      "Degree:  100.0 , Velocity:  6.0 Action:  -2.0\n",
      "Degree:  100.0 , Velocity:  7.0 Action:  0.25\n",
      "Degree:  100.0 , Velocity:  8.0 Action:  0.25\n",
      "\n",
      "Degree:  120.0 , Velocity:  -8.0 Action:  2.0\n",
      "Degree:  120.0 , Velocity:  -7.0 Action:  0.0\n",
      "Degree:  120.0 , Velocity:  -6.0 Action:  0.75\n",
      "Degree:  120.0 , Velocity:  -5.0 Action:  -0.25\n",
      "Degree:  120.0 , Velocity:  -4.0 Action:  -2.0\n",
      "Degree:  120.0 , Velocity:  -3.0 Action:  -1.25\n",
      "Degree:  120.0 , Velocity:  -2.0 Action:  -2.0\n",
      "Degree:  120.0 , Velocity:  -1.0 Action:  -2.0\n",
      "Degree:  120.0 , Velocity:  0.0 Action:  -2.0\n",
      "Degree:  120.0 , Velocity:  1.0 Action:  -2.0\n",
      "Degree:  120.0 , Velocity:  2.0 Action:  -2.0\n",
      "Degree:  120.0 , Velocity:  3.0 Action:  -2.0\n",
      "Degree:  120.0 , Velocity:  4.0 Action:  1.5\n",
      "Degree:  120.0 , Velocity:  5.0 Action:  -0.5\n",
      "Degree:  120.0 , Velocity:  6.0 Action:  1.5\n",
      "Degree:  120.0 , Velocity:  7.0 Action:  0.75\n",
      "Degree:  120.0 , Velocity:  8.0 Action:  0.75\n",
      "\n",
      "Degree:  140.0 , Velocity:  -8.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  -7.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  -6.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  -5.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  -4.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  -3.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  -2.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  -1.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  0.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  1.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  2.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  3.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  4.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  5.0 Action:  -0.5\n",
      "Degree:  140.0 , Velocity:  6.0 Action:  -2.0\n",
      "Degree:  140.0 , Velocity:  7.0 Action:  0.75\n",
      "Degree:  140.0 , Velocity:  8.0 Action:  0.25\n",
      "\n",
      "Degree:  160.0 , Velocity:  -8.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  -7.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  -6.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  -5.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  -4.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  -3.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  -2.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  -1.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  0.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  1.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  2.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  3.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  4.0 Action:  -2.0\n",
      "Degree:  160.0 , Velocity:  5.0 Action:  -1.75\n",
      "Degree:  160.0 , Velocity:  6.0 Action:  1.25\n",
      "Degree:  160.0 , Velocity:  7.0 Action:  -0.75\n",
      "Degree:  160.0 , Velocity:  8.0 Action:  -2.0\n",
      "\n",
      "Degree:  180.0 , Velocity:  -8.0 Action:  2.0\n",
      "Degree:  180.0 , Velocity:  -7.0 Action:  0.75\n",
      "Degree:  180.0 , Velocity:  -6.0 Action:  -1.5\n",
      "Degree:  180.0 , Velocity:  -5.0 Action:  0.25\n",
      "Degree:  180.0 , Velocity:  -4.0 Action:  -1.5\n",
      "Degree:  180.0 , Velocity:  -3.0 Action:  1.0\n",
      "Degree:  180.0 , Velocity:  -2.0 Action:  2.0\n",
      "Degree:  180.0 , Velocity:  -1.0 Action:  0.75\n",
      "Degree:  180.0 , Velocity:  0.0 Action:  1.25\n",
      "Degree:  180.0 , Velocity:  1.0 Action:  -2.0\n",
      "Degree:  180.0 , Velocity:  2.0 Action:  -2.0\n",
      "Degree:  180.0 , Velocity:  3.0 Action:  -2.0\n",
      "Degree:  180.0 , Velocity:  4.0 Action:  1.25\n",
      "Degree:  180.0 , Velocity:  5.0 Action:  -1.25\n",
      "Degree:  180.0 , Velocity:  6.0 Action:  0.75\n",
      "Degree:  180.0 , Velocity:  7.0 Action:  -2.0\n",
      "Degree:  180.0 , Velocity:  8.0 Action:  0.5\n"
     ]
    }
   ],
   "source": [
    "for s0 in larry.state_space[0]:\n",
    "    print(\"\")\n",
    "    for s1 in larry.state_space[1]:\n",
    "        index = larry.map_to_index([s0,s1])\n",
    "        print(\"Degree: \", s0, \", Velocity: \", s1, \"Action: \", policy[index[0], index[1]])\n",
    "        # print(\"Degree: {}, Velocity: {}, Value: {}\".format(s0, s1, value_function[s0, s1]))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Policy Iteration\n",
    "    \n",
    "    Gives convergence towards the optimal policy by iteratively\n",
    "    performing Policy Evaluation and Policy Improvement\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def policy_iteration(disc, theta, gamma):        \n",
    "    \n",
    "    print(\"Policy iteration...\")\n",
    "\n",
    "    value_function = np.ones(shape=disc.state_space_size)\n",
    "    policy = np.zeros(shape=disc.state_space_size)\n",
    "\n",
    "    \n",
    "    def policy_evaluation(theta, gamma):\n",
    "        print()\n",
    "        print(\"Evaluating policy\")\n",
    "        delta = theta\n",
    "        while delta >= theta:\n",
    "            delta = 0\n",
    "            # Iteratate over discrete state space\n",
    "            for s0 in disc.state_space[0]:\n",
    "                for s1 in disc.state_space[1]:\n",
    "                    for s2 in disc.state_space[2]:\n",
    "                        \n",
    "                        # Get index for state \n",
    "                        # The method already iterates over a discretized state space\n",
    "                        # But the states need to get mapped to a positive index do to possible 'negative' states\n",
    "                        index = disc.map_to_index([s0, s1, s2])\n",
    "                        \n",
    "                        v = value_function[index[0], index[1], index[2]]\n",
    "                        \n",
    "                        \"\"\"\n",
    "                         V(s) = Sum...p(s',r|s,pi(s))[r+gamma*V(s')]\n",
    "                         \n",
    "                        \"\"\"\n",
    "                        a = policy[index[0], index[1], index[2]]\n",
    "                        \n",
    "                        # input for regression\n",
    "                        x = np.array([s0, s1, s2, a]).reshape(1, -1)\n",
    "                        \n",
    "                        # Predict next state and reward with regressors\n",
    "                        next_s = regressorState.predict(x).T.reshape(-1,)\n",
    "                        r = regressorReward.predict(x)      \n",
    "                        \n",
    "                        next_index = disc.map_to_index([next_s[0], next_s[1], next_s[2]])\n",
    "                                          \n",
    "                        value_function[index[0], index[1], index[2]] = r + gamma*value_function[next_index[0],\n",
    "                                                                              next_index[1], next_index[2]]\n",
    "                                          \n",
    "                        delta = max(delta, v - value_function[index[0], index[1], index[2]])\n",
    "            print(\"Delta: \", delta)\n",
    "    \n",
    "    \n",
    "    def policy_improvement(gamma):\n",
    "        print()\n",
    "        print(\"Improving policy\")\n",
    "        policy_stable = True\n",
    "        for s0 in disc.state_space[0]:\n",
    "                for s1 in disc.state_space[1]:\n",
    "                    for s2 in disc.state_space[2]:\n",
    "                        \n",
    "                        # Indexing\n",
    "                        index = disc.map_to_index([s0, s1, s2])\n",
    "                        \n",
    "                        old_action = policy[index[0], index[1], index[2]]\n",
    "                        \n",
    "                        \"\"\"\n",
    "                            pi(s) = argmax_a ... \n",
    "                            We do not have to care about the prob. distribution,\n",
    "                            as we have a deterministic env.\n",
    "                            \n",
    "                        \"\"\"\n",
    "                        # Iterate over all actions and get the one with max. expected reward\n",
    "                        amax = 2\n",
    "                        rmax = -100\n",
    "                        for a in disc.action_space:\n",
    "                            x = np.array([s0, s1, s2, a])\n",
    "                            x = x.reshape(1,-1)\n",
    "                            next_s = regressorState.predict(x).T.reshape(-1,)\n",
    "                            next_index = disc.map_to_index([next_s[0], next_s[1], next_s[2]])\n",
    "                            r = regressorReward.predict(x)\n",
    "                            expected_reward = r + gamma*value_function[next_index[0], next_index[1], next_index[2]]\n",
    "                            if rmax < expected_reward:\n",
    "                                amax = a\n",
    "                                rmax = expected_reward \n",
    "                        policy[index[0], index[1], index[2]] = amax # TODO\n",
    "                        \n",
    "                        if old_action != policy[index[0], index[1], index[2]]:\n",
    "                            policy_stable = False\n",
    "                            \n",
    "        print(\"Policy stable: \", policy_stable)\n",
    "        return policy_stable\n",
    "        \n",
    "    # Run until policy is stable\n",
    "    stable_policy = False\n",
    "    while not stable_policy:\n",
    "        policy_evaluation(theta, gamma)\n",
    "        stable_policy = policy_improvement(gamma)\n",
    "    \n",
    "    print()\n",
    "    print(\"...done\")\n",
    "    return value_function, policy\n",
    "    \n",
    "# value_function, policy = policy_iteration(larry, theta=1, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Episode 1 finished after 200 timesteps\n",
      "Episode 2 finished after 200 timesteps\n",
      "Episode 3 finished after 200 timesteps\n",
      "Episode 4 finished after 200 timesteps\n",
      "Episode 5 finished after 200 timesteps\n",
      "Episode 6 finished after 200 timesteps\n",
      "Episode 7 finished after 200 timesteps\n",
      "Episode 8 finished after 200 timesteps\n",
      "Episode 9 finished after 200 timesteps\n",
      "Episode 10 finished after 200 timesteps\n",
      "Episode 11 finished after 200 timesteps\n",
      "Episode 12 finished after 200 timesteps\n",
      "Episode 13 finished after 200 timesteps\n",
      "Episode 14 finished after 200 timesteps\n",
      "Episode 15 finished after 200 timesteps\n",
      "Episode 16 finished after 200 timesteps\n",
      "Episode 17 finished after 200 timesteps\n",
      "Episode 18 finished after 200 timesteps\n",
      "Episode 19 finished after 200 timesteps\n",
      "Episode 20 finished after 200 timesteps\n",
      "Episode 21 finished after 200 timesteps\n",
      "Episode 22 finished after 200 timesteps\n",
      "Episode 23 finished after 200 timesteps\n",
      "Episode 24 finished after 200 timesteps\n",
      "Episode 25 finished after 200 timesteps\n",
      "Episode 26 finished after 200 timesteps\n",
      "Episode 27 finished after 200 timesteps\n",
      "Episode 28 finished after 200 timesteps\n",
      "Episode 29 finished after 200 timesteps\n",
      "Episode 30 finished after 200 timesteps\n",
      "Episode 31 finished after 200 timesteps\n",
      "Episode 32 finished after 200 timesteps\n",
      "Episode 33 finished after 200 timesteps\n",
      "Episode 34 finished after 200 timesteps\n",
      "Episode 35 finished after 200 timesteps\n",
      "Episode 36 finished after 200 timesteps\n",
      "Episode 37 finished after 200 timesteps\n",
      "Episode 38 finished after 200 timesteps\n",
      "Episode 39 finished after 200 timesteps\n",
      "Episode 40 finished after 200 timesteps\n",
      "Episode 41 finished after 200 timesteps\n",
      "Episode 42 finished after 200 timesteps\n",
      "Episode 43 finished after 200 timesteps\n",
      "Episode 44 finished after 200 timesteps\n",
      "Episode 45 finished after 200 timesteps\n",
      "Episode 46 finished after 200 timesteps\n",
      "Episode 47 finished after 200 timesteps\n",
      "Episode 48 finished after 200 timesteps\n",
      "Episode 49 finished after 200 timesteps\n",
      "Episode 50 finished after 200 timesteps\n",
      "Episode 51 finished after 200 timesteps\n",
      "Episode 52 finished after 200 timesteps\n",
      "Episode 53 finished after 200 timesteps\n",
      "Episode 54 finished after 200 timesteps\n",
      "Episode 55 finished after 200 timesteps\n",
      "Episode 56 finished after 200 timesteps\n",
      "Episode 57 finished after 200 timesteps\n",
      "Episode 58 finished after 200 timesteps\n",
      "Episode 59 finished after 200 timesteps\n",
      "Episode 60 finished after 200 timesteps\n",
      "Episode 61 finished after 200 timesteps\n",
      "Episode 62 finished after 200 timesteps\n",
      "Episode 63 finished after 200 timesteps\n",
      "Episode 64 finished after 200 timesteps\n",
      "Episode 65 finished after 200 timesteps\n",
      "Episode 66 finished after 200 timesteps\n",
      "Episode 67 finished after 200 timesteps\n",
      "Episode 68 finished after 200 timesteps\n",
      "Episode 69 finished after 200 timesteps\n",
      "Episode 70 finished after 200 timesteps\n",
      "Episode 71 finished after 200 timesteps\n",
      "Episode 72 finished after 200 timesteps\n",
      "Episode 73 finished after 200 timesteps\n",
      "Episode 74 finished after 200 timesteps\n",
      "Episode 75 finished after 200 timesteps\n",
      "Episode 76 finished after 200 timesteps\n",
      "Episode 77 finished after 200 timesteps\n",
      "Episode 78 finished after 200 timesteps\n",
      "Episode 79 finished after 200 timesteps\n",
      "Episode 80 finished after 200 timesteps\n",
      "Episode 81 finished after 200 timesteps\n",
      "Episode 82 finished after 200 timesteps\n",
      "Episode 83 finished after 200 timesteps\n",
      "Episode 84 finished after 200 timesteps\n",
      "Episode 85 finished after 200 timesteps\n",
      "Episode 86 finished after 200 timesteps\n",
      "Episode 87 finished after 200 timesteps\n",
      "Episode 88 finished after 200 timesteps\n",
      "Episode 89 finished after 200 timesteps\n",
      "Episode 90 finished after 200 timesteps\n",
      "Episode 91 finished after 200 timesteps\n",
      "Episode 92 finished after 200 timesteps\n",
      "Episode 93 finished after 200 timesteps\n",
      "Episode 94 finished after 200 timesteps\n",
      "Episode 95 finished after 200 timesteps\n",
      "Episode 96 finished after 200 timesteps\n",
      "Episode 97 finished after 200 timesteps\n",
      "Episode 98 finished after 200 timesteps\n",
      "Episode 99 finished after 200 timesteps\n",
      "Episode 100 finished after 200 timesteps\n",
      "...done\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Evaluation stuff to see the predictions, discretizations and learned functions in action\n",
    "\n",
    "\"\"\"\n",
    "rewards_per_episode = []\n",
    "\n",
    "episodes = 100\n",
    "\n",
    "print(\"Evaluating...\")\n",
    "\n",
    "for e in range(episodes):\n",
    "    \n",
    "    # Discretize first state\n",
    "    state = env.reset()\n",
    "    state = np.array([my_arctan(state[0], state[1]), state[2]])\n",
    "    index = larry.map_to_index(state)\n",
    "    \n",
    "    cumulative_reward = [0]\n",
    "    \n",
    "    for t in range(200):\n",
    "        # Render environment\n",
    "        env.render()\n",
    "\n",
    "        # Do step according to policy and get observation and reward\n",
    "        action = np.array([policy[index[0], index[1]]])\n",
    "\n",
    "        #action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        state = np.array([my_arctan(observation[0], observation[1]), observation[2]])\n",
    "        \n",
    "        cumulative_reward.append(cumulative_reward[-1]+reward)\n",
    "        \n",
    "        # Discretize observed state\n",
    "        index = larry.map_to_index(state)\n",
    "\n",
    "        if done:\n",
    "            print(\"Episode {} finished after {} timesteps\".format(e+1, t+1))\n",
    "            break\n",
    "    \n",
    "    rewards_per_episode.append(cumulative_reward)\n",
    "\n",
    "print(\"...done\")    \n",
    "\n",
    "# TODO: Look at calculation of mean cumulative rewards\n",
    "# Average reward over episodes\n",
    "rewards = np.average(rewards_per_episode, axis=0)\n",
    "        \n",
    "env.close()\n",
    "\n",
    "# Plot rewards per timestep averaged over episodes\n",
    "plt.figure()\n",
    "plt.plot(rewards, label='Cumulative reward per timestep, averaged over {} episodes'.format(episodes))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
