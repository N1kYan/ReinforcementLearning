{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.]\n",
      "[-1. -1. -8.]\n"
     ]
    }
   ],
   "source": [
    "# Create gym environment\n",
    "env = gym.make('Pendulum-v0')\n",
    "env.reset()\n",
    "#action space is a Box(1,) with values between [-2,2], joint effort\n",
    "print(env.action_space.low)\n",
    "#observation space is 3d angle of pendulum cos, sin, velocity max:1,1,8; min:-1,-1,8\n",
    "print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.55891524  0.82922479  0.47504008]\n",
      "[0.19525401]\n",
      "[-0.6047002   0.79645318  1.12624677] -4.704952469306733 False {}\n"
     ]
    }
   ],
   "source": [
    "#reward formular: -(theta^2 + 0.1*theta_dt^2 + 0.001*action^2) (-16.27 is worst, 0 best)\n",
    "print(env.reset())\n",
    "a = env.action_space.sample()\n",
    "print(a)\n",
    "state, reward, done, info = env.step(a)\n",
    "print(state, reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning episodes\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Discretization import Discretization\n",
    "\n",
    "larry = Discretization(\"easy\", \"Pendulum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression...\n",
      "...done\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xl81NW9+P/XmTWTfWVJAgQQZAkQEEFAbBWxaC16XdFapdrrVa+l9+tPW217taW2V67W2tvNarVYa12rlor7VsEFWUT2fQlhCdn3yWzn98eZhElIyASyTPJ5Px+PeTDzmc/MnPlkeH/O5302pbVGCCGENdh6uwBCCCF6jgR9IYSwEAn6QghhIRL0hRDCQiToCyGEhUjQF0IIC5GgL4QQFiJBXwghLESCvhBCWIijtwvQWmZmps7Ly+vtYgghRJ+ydu3aUq11Vkf7xVzQz8vLY82aNb1dDCGE6FOUUvuj2U/SO0IIYSES9IUQwkIk6AshhIXEXE5fiP7M7/dTVFSE1+vt7aKIPiouLo7c3FycTudJvV6CvhA9qKioiKSkJPLy8lBK9XZxRB+jtaasrIyioiKGDx9+Uu8h6R0hepDX6yUjI0MCvjgpSikyMjJO6UpRgr4QPUwCvjgVp/r7sUzQP1Bez4fbj/Z2MYQQoldZJug/9ck+vvvsF71dDCF6XWJiYrd/xosvvsjYsWM599xzu/2zukteXh6lpaXHbY/8bmvWrGHRokUAfPjhh3zyySfN+7366qts2bKl+fG9997Lu+++2/0F74BlGnJ9wRANvmBvF0MIS3jiiSd4/PHHOfvss6PaPxAI4HC0HY601mitsdm6r456os9vrfV3mzp1KmCCfmJiIjNnzgRM0L/44osZN24cAIsXL+6GkneeZWr6wZAmENIEgqHeLooQMWffvn2cd955TJw4kTlz5lBYWAiYWm1+fj6TJk3inHPOAWDz5s1MmzaNgoICJk6cyM6dO1u81+LFi1m5ciU33XQTd911F16vl29/+9tMmDCByZMn88EHHwCwdOlS5s+fz3nnncecOXOOK8/pp5/O9ddfT35+PgcOHODtt99mxowZTJkyhSuvvJLa2lpWr17NZZddBsA//vEPPB4PPp8Pr9fLiBEjAHj88cc588wzmTRpEpdffjn19fUALFy4kFtuuYXp06fz/e9/n7KyMi644ALGjx/Pd77zHbTWxx2n1t/tww8/5OKLL2bfvn08+uij/OpXv6KgoIB//etfLFu2jLvuuouCggJ2797NwoULeemllwBzFXHfffcxZcoUJkyYwLZt2wAoKSlh7ty5zWUYNmxYm1cbp8IyNf1Q+A/oC4Zw2C1zrhMx7Kf/3MyWQ9Vd+p7jspO57xvjO/267373u9xwww3ccMMNPPnkkyxatIhXX32VxYsX89Zbb5GTk0NlZSUAjz76KN/73vf45je/ic/nIxhseQV977338v777/PQQw8xdepUfvnLX6KUYuPGjWzbto0LLriAHTt2ALBu3To2bNhAenr6cWXauXMnTz31FGeddRalpaXcf//9vPvuuyQkJLBkyRIefvhhfvjDH7J+/XoAVqxYQX5+PqtXryYQCDB9+nQALrvsMv793/8dgB//+Mc88cQTfPe73wVMF9pPPvkEu93OokWLOPvss7n33ntZvnw5TzzxxHFlav3dPvzwQ8AE8VtuuYXExETuvPNOAObPn8/FF1/MFVdc0eYxz8zMZN26dfz+97/noYce4k9/+hM//elPOe+887jnnnt488032yzDqbJM0A8ETdD3+kPEu3q5MELEmE8//ZSXX34ZgG9961t8//vfB2DWrFksXLiQq666qrlGPWPGDH7+859TVFTEZZddxqhRo0743itXrmwOsmPGjGHYsGHNQX/u3LltBnyAYcOGcdZZZwHw2WefsWXLFmbNmgWAz+djxowZOBwORo4cydatW/n888+54447+OijjwgGg8yePRuATZs28eMf/5jKykpqa2v52te+1vwZV155JXa7HYCPPvqo+Rh8/etfJy0trZNHsXOajucZZ5zR/LkrV67klVdeAWDevHndUgbLBP1guKbfGJC8vogNJ1Mj72mPPvooq1atYvny5ZxxxhmsXbuWa6+9lunTp7N8+XIuuugi/vjHP3Leeeed1PsnJCRE9ZzWmrlz5/Lss88et98555zDG2+8gdPp5Pzzz2fhwoUEg0EefPBBwKRxXn31VSZNmsTSpUuba+cdfX53c7vdANjtdgKBQI99rmXyHKFQOOj7JacvRGszZ87kueeeA+CZZ55priXv3r2b6dOns3jxYrKysjhw4AB79uxhxIgRLFq0iEsuuYQNGzac8L1nz57NM888A8COHTsoLCzk9NNP71T5zjrrLD7++GN27doFQF1dXfPVwuzZs3nkkUeYMWMGWVlZlJWVsX37dvLz8wGoqalh8ODB+P3+5nK05ZxzzuFvf/sbAG+88QYVFRWdKmNSUhI1NTXtPo7GrFmzeOGFFwB4++23O12GaFgm6IezOzQGJOgLa6uvryc3N7f59vDDD/Ob3/yGP//5z0ycOJGnn36aX//61wDcddddTJgwgfz8fGbOnMmkSZN44YUXyM/Pp6CggE2bNnH99def8PNuu+02QqEQEyZM4Oqrr2bp0qXNtdxoZWVlsXTpUq655homTpzIjBkzmhs/p0+fTnFxcXND88SJE5kwYULzIKaf/exnTJ8+nVmzZjFmzJh2P+O+++7jo48+Yvz48bz88ssMHTq0U2X8xje+wSuvvEJBQQErVqxgwYIFPPjgg0yePJndu3dH9R733Xcfb7/9Nvn5+bz44osMGjSIpKSkTpWjI6qtFureNHXqVN0di6j85zPrWL7xMMtun8XE3NQuf38horF161bGjh3b28UQMaqxsRG73Y7D4eDTTz/l1ltvbW6ojtTW70gptVZrPbWjz7BOTr8pvSM1fSFEjCosLOSqq64iFArhcrl4/PHHu/wzLBP0A6Gm3jvSkCuEiE2jRo3iiy+6d+YAy+T0m/rpS0OuEMLKLBP0Jb0jhBAWCvoh6acvhBDWCfpS0xdCCAsF/UDz4Cyp6Qtr68tTKz/yyCPNE6Z1xX6Rtm3bRkFBQXO/+qbZMvft29c8aAtg/fr1vP76682Ply1bxgMPPNCpz+pNlgn6TSNyvVLTF6LbNU0/3DSjZkeinYagO4P+q6++yhVXXMEXX3zByJEjm+fG7yjoz58/n7vvvrtTn9Wbogr6Sql5SqntSqldSqnjvp1Syq2Uej78/CqlVF6r54cqpWqVUnd2TbE7Lyi9d4RoV6xNrVxXV8fXv/51Jk2aRH5+Ps8//zz/93//x6FDhzj33HObryBuvfVWpk6dyvjx47nvvvsA2tyvrWmZI73++us88sgj/OEPf2h+TdMV0d13382KFSsoKChgyZIl3HvvvTz//PMUFBTw/PPPs3TpUm6//XbAzPOzaNEiZs6cyYgRI5qnUg6FQtx2222MGTOGuXPnctFFFzU/19M67KevlLIDvwPmAkXAaqXUMq31lojdbgIqtNanKaUWAEuAqyOefxh4o+uK3XnNc+9IQ66IFW/cDUc2du17DpoAF3Y+1RBrUyu/+eabZGdns3z5cgCqqqpISUnh4Ycf5oMPPiAzMxOAn//856SnpxMMBpkzZw4bNmxg0aJFLfZrb1rme++9t/nzLrroouOmRm7ywAMP8NBDD/Haa68BMHDgQNasWcNvf/tbwJy8Ih0+fJiVK1eybds25s+fzxVXXMHLL7/Mvn372LJlC0ePHmXs2LHceOONnf47dYVoavrTgF1a6z1aax/wHHBJq30uAZ4K338JmKPCE18opS4F9gKbu6bIJ+fYLJtS0xeitU8//ZRrr70WMFMrr1y5Ejg2tfLjjz/eHNxnzJjBL37xC5YsWcL+/fvxeDwnfO+VK1dy3XXXAdFPrTxhwgTeeecdfvCDH7BixQpSUlLafO8XXniBKVOmMHnyZDZv3txiecImkdMyFxQU8NRTT7F///4oj0znXXrppdhsNsaNG0dxcTFgjsGVV16JzWZj0KBBvbqMZDQjcnOAAxGPi4Dp7e2jtQ4opaqADKWUF/gB5iqh11I7cGw+fanpi5hxEjXyntZbUyuPHj2adevW8frrr/PjH/+YOXPmtKiZA+zdu5eHHnqI1atXk5aWxsKFC/F6vce914mmZe4OkZPJxdrcZtD9Dbk/AX6lta490U5KqZuVUmuUUmtKSkq6pSAyIleI9sXa1MqHDh0iPj6e6667jrvuuot169YBLacrrq6uJiEhgZSUFIqLi3njjWMZ5Mj9TjQtczS6asrkv//974RCIYqLi1vM6d/ToqnpHwSGRDzODW9ra58ipZQDSAHKMFcEVyil/hdIBUJKKa/W+reRL9ZaPwY8BmaWzZP5Ih0JSu8dIYBjUys3ueOOO/jNb37Dt7/9bR588EGysrL485//DJiplXfu3InWmjlz5jBp0iSWLFnC008/jdPpZNCgQfzwhz884efddttt3HrrrUyYMAGHwxHV1MobN27krrvuwmaz4XQ6+cMf/gDAzTffzLx588jOzuaDDz5g8uTJjBkzhiFDhjSvqtXWfk3TMjc2NgJw//33M3r06KiO18SJE7Hb7UyaNImFCxdyww038MADD1BQUMA999wT1XtcfvnlvPfee4wbN44hQ4YwZcqUdlNW3a3DqZXDQXwHMAcT3FcD12qtN0fs85/ABK31LeGG3Mu01le1ep+fALVa64dO9HndNbXyuQ99yN7SOi4YN5DHru9w9lEhuoVMrWxdtbW1JCYmUlZWxrRp0/j4448ZNGjQSb1Xt06tHM7R3w68BdiBJ7XWm5VSi4E1WutlwBPA00qpXUA5sOAkvke3khG5QojedPHFF1NZWYnP5+O///u/Tzrgn6qoplbWWr8OvN5q270R973AlR28x09OonxdJihdNoUQvag38/iRLDMiV2r6IlbEYo8O0Xec6u/HOkFfNy2iIkFf9J64uDjKysok8IuTorWmrKyMuLi4k34Py6ycJSNyRSzIzc2lqKiI7uqaLPq/uLi4Fr2vOssyQV/m3hGxwOl0Mnz48N4uhrAw66R3JKcvhBBWDPqS3hFCWJcFg77U9IUQ1mWZoN80944vEGpu1BVCCKuxTNAPhjQOmwLAF5TavhDCmiwR9LXWhDTEu+yA9OARQliXJYJ+Uz4/3mV6qEpjrhDCqqwR9HVT0A/X9KUxVwhhUZYI+qFwjPc0B32p6QshrMkSQb+ppp8QTu/I/DtCCKuyRtAP5/Slpi+EsDpLBf0Et/TeEUJYm6WCvsfZ1HtHgr4QwposEfRDx/XekfSOEMKaLBH0m/vpu6XLphDC2qwV9J1NvXekpi+EsCZLBP3j0ztS0xdCWJMlgn6gdXpHeu8IISzKEkE/FGpZ05f0jhDCqiwR9JtG5LoddpSSqZWFENZljaAfrunbbQqX3YZPcvpCCIuyRNBvmnDNrhRuh00acoUQlmWJoB8IR327TeFy2CXoCyEsyxJBv6nLps3WVNOXhlwhhDVZIug3tds6bAq3U3L6QgjrskjQD9f0lWnIlfSOEMKqLBH0m9I7dpvC7ZScvhDCuiwR9APNXTbBbbfhk5y+EMKiLBH0QxHpHbdT0jtCCOuyRNBvyuk7bDbcDmnIFUJYlzWCfnOXTXDJ4CwhhIVZIuiHIqZhcDvs0k9fCGFZUQV9pdQ8pdR2pdQupdTdbTzvVko9H35+lVIqL7x9mlJqffj2pVLq37q2+NFpbshVMveOEMLaOgz6Sik78DvgQmAccI1Salyr3W4CKrTWpwG/ApaEt28CpmqtC4B5wB+VUo6uKny0WozIlYZcIYSFRVPTnwbs0lrv0Vr7gOeAS1rtcwnwVPj+S8AcpZTSWtdrrQPh7XGA7opCd1ZQavpCCAFEF/RzgAMRj4vC29rcJxzkq4AMAKXUdKXUZmAjcEvESaCZUupmpdQapdSakpKSzn+LDkROrSw1fSGElXV7Q67WepXWejxwJnCPUiqujX0e01pP1VpPzcrK6vIytBiR67ATDGkCspCKEMKCogn6B4EhEY9zw9va3Cecs08ByiJ30FpvBWqB/JMt7Mlqiu9mamXzlWX1LCGEFUUT9FcDo5RSw5VSLmABsKzVPsuAG8L3rwDe11rr8GscAEqpYcAYYF+XlLwTguH59G3hRVRAFkcXQlhThz1ptNYBpdTtwFuAHXhSa71ZKbUYWKO1XgY8ATytlNoFlGNODABnA3crpfxACLhNa13aHV/kRFoslyg1fSGEhUXVfVJr/Trweqtt90bc9wJXtvG6p4GnT7GMpywY7jPUlNMHqekLIazJciNyj9X0ZVSuEMJ6LBH0m+besUfk9L1S0xdCWJA1gn7o2IRrbsnpCyEszFJB366OpXckpy+EsCJrBf3IhlyZaVMIYUGWCPohrbEpUBE5fZl/RwhhRZYI+sGQxm5TwLGcvsy/I4SwIssEfZtqCvomvSM1fSGEFVkm6DfV9F1S0xdCWJg1gr5uK70jDblCCOuxRNAPtVHTl/SOEMKKLBH0g1pjV9KQK4QQ1gj6IbM+LoDDbsOmpKYvhLAmiwT9UHNNH0wPHsnpCyGsyCJBn+acPoDbKYujCyGsyRJBPxTRewfAZZfF0YUQ1mSJoB/ZTx9MTV+CvhDCiqwR9MNz7zRx2SW9I4SwJmsE/WCrmr405AohLMoaQV9r7LZjX9XlkPSOEMKaLBH0zYjcY4/dEvSFEBZliaAfOSIXwO20S05fCGFJ1gj6Id08Iheky6YQwrosE/Rb1vRtnWrIrWrw89N/bmbzoaruKJ4QQvQYywT9yJq+u5NdNv+x/iB//ngf83/7MU9/tr87iiiEED3CEkE/pDWOUxic9eH2EnLTPIwakMhLa4u6o4hCCNEjLBH0W4/I7czgLK8/yCe7S5kzZgDDMuJp8AW6q5hCCNHtrBH0Nc1r5ILpvRNtTv/zveV4/SG+cnoW8S4HDX4Z1CWE6LusEfRDoVYjck16R2vd4Ws/3F6Cy2FjxohM4px2GnwS9IUQfZdFgn7Lmr7HZUfr6FbP+mR3KdPy0vG47MS77NRL0BdC9GGWCPqhUMuG3CS3A4Aa74nz815/kJ1Ha5k8NBWAeJedBn8wqisEIYSIRZYI+sFW8+knhIN+XeOJg/7Ww9UEQ5rx2SkAxDmjv0IQQohYZImgH2rVTz8xHPRrOwj6mw5VA5CfkwyYmj4geX0hRJ9liaBv5t459jjaoL/5YBVp8U5yUj3AsaBfLz14hBB9lCWCfiDYqqYfFw76HeT0Nx2qIj8nBRVuBI5zNtX0pa++EKJviiroK6XmKaW2K6V2KaXubuN5t1Lq+fDzq5RSeeHtc5VSa5VSG8P/nte1xY9O6xG5zTn9EwTvxkCQ7UdqmvP5APEu87oGn+T0hRB9U4dBXyllB34HXAiMA65RSo1rtdtNQIXW+jTgV8CS8PZS4Bta6wnADcDTXVXwaDQGgtQ2Bo4bkRtN752dxbX4g5oJOceCvidc06+Xmr4Qoo9yRLHPNGCX1noPgFLqOeASYEvEPpcAPwnffwn4rVJKaa2/iNhnM+BRSrm11o2nXPIo/PLtHazYWUpI6xb99KPpvbP1sGnEHTs4qXmbp6khV3L6Qog+Kpr0Tg5wIOJxUXhbm/torQNAFZDRap/LgXVtBXyl1M1KqTVKqTUlJSXRlr1De0vr2Flcg7/VGrnxLjtKnbghd3dJHU67Ymh6fIvXgfTeEUL0XT3SkKuUGo9J+fxHW89rrR/TWk/VWk/Nysrqss+tavATCGmqGvwtavpKKRLdDmobA2w9XM2PXtlIKNRywNWeklqGZSTgiFhn8Vh6R4K+EKJviiboHwSGRDzODW9rcx+llANIAcrCj3OBV4Drtda7T7XAnVHd4G++H9mQC6bbZq03wDtbinlmVSFldb4Wz+8uqWVkVkKLbfGS3hFC9HHRBP3VwCil1HCllAtYACxrtc8yTEMtwBXA+1prrZRKBZYDd2utP+6qQkerKiLo29sI+nW+AGW1JttU7T22byAYorC8nhFZiS1e45H0jhCij+sw6Idz9LcDbwFbgRe01puVUouVUvPDuz0BZCildgF3AE3dOm8HTgPuVUqtD98GdPm3aEdl/bFAbmsV9BPcDmq8AUprTQ0/sifPgYoG/EHNyNZB3yk1fSFE3xZN7x201q8Dr7fadm/EfS9wZRuvux+4/xTLeFJ8gVCL4By5Ri5AUpyDusZA82Iqkamg3UdrARjRKr3jsNtw2W2S0xdC9FlRBf2+KDK1A23U9F0Oiqu9NLXfRtb095SaoD8ys2VNHyDOaZMRuUKIPssyQf+4htw4B3WNweaBVpE5/d1H68hMdJES7zzufWX1LCFEX9Zv595pCvoJ4cbXthpyK+t9VITz/jURQX9Pae1xjbhNZCEVIURf1o+DvmmgHTXQjKi1qbZ67xwL3tUNx1I2BysaGJIWT1vinHa8UtMXQvRR/Tjom5r7mEEm6NtbfdOmqRiaRNb0K+r9pCccn9oBqekLIfq2/hv0w2mb0e3V9ONaBv3qcEOu1x+kwR8kLcHV5vt6JOgLIfqw/hv0w+mapqDfuiE3KaKmH+e0Ndf0K+pNWigtvp2gL+kdIUQf1o+Dvp9Et4PcNLPqVeuG3Mj0Tl5GQnNOv6LOBP+0NnrugKR3hBB9W78N+pUNPlI8Toamx7NozijOHdNyIHDTkokOmyI3Lb65y2ZluKaf2l5NX4K+EKIP67f99Ksb/CR7nNhsijvmjj7u+aagn57gIsXjZOthU9MvDwf99PZy+k6HpHeEEH1Wv63pVzX4SfG0f05rasjNSHSTFOdoruk39dtPPWF6J4DWus3nhRAilvXzoN924AZIcJtBW5mJLpI9TmobA4RCmsrwFMupnvbTOyENvqCskyuE6Hv6bdCvrPe3G7gBktzmhJCZ6CY5zoHWUOsLUF7vI8ntwOVo+9A0z7QpeX0hRB/Ub4N+VYO/zblzmsQ5zYyZWUlukuPMftUNfnOyaGdgFhybU//OFzfwnafWdG2hhRCim/XLhlyvP0hjIHTC9I5Sike/NYUxg5L58kAlYGbarKj3tdtHH46tnvXu1mJcdhv+YAhneLjvhqJKxgxKbvcqQQghelu/jE5Nc+MnnyDoA5w3ZiDZqZ7m/aob/FTU+9vtrgnH0jtg8vo7i800zEervVz6u4/526r9p1p8IYToNv0z6IenVEiOi+5CJim8X403QEWdj/QTpIWa0jtNVxGbDlUBsKe0jpCGdYWVJ11uIYTobv0y6DcGTCOr22HvYE+jOafv9VNR7zthTT/eZU4Q3zl7OAkuO5sPmqBfWFYPwMbwYyGEiEX9NOib7pRuZ3Rfr6mmX17no8YbOGFOf0JOCovmjOL6GXmMz05h06FqAPaX1wGwt7TuuAVchBAiVvTLoN+07q07ygbVpHBNv6iiAaDdaZUBXA4bd8wdTUq8k/E5yWw5VE0wpNkfrukDzbV/IYSINf0y6Dd2Mui7HDbinDb2l5na+onSO5Hys1No8AfZW1pLYXk9+TnJAGyQoC+EiFH9M+j7O5fTBxiZlcjHu8qA9qdVbm1CbgpgGm/3l9UzKTeVIekeNhZJ0BdCxKZ+GfSbpkiItqYP8LNL8wmEzOvam3entVEDEhmY7OYf6w9S1eBnWEY8E3NS2XBQevAIIWJTvwz6jX4TvDszSGrK0DT+89zTsNsUg1PionqNUorzxgxovkIYmp7AhNwUDpQ3UBGew0cIIWJJ/wz6zTn96NM7AHfMHc3KH5xLRqI76tfMGTOw+f7Q9Hgm5piUj3TdFELEon4a9Jty+p37ekopBqd4OvWaWadlNn/O0Ix4xkvQF0LEsH4Z9H2d7Kd/KjwuO7NHZTEw2U2i20GKx8nwzAQ2FEleXwgRe/rlhGtN6R2XvWfOafdfmk9pbWPz4wk5KazZV94jny2EEJ3RL2v6jYEgdpvC0UNBf1BKHPnhtA7AxNwUDlV5KakxJ4LaxgDBkKy0JYToff0y6PsCoU7n87vShPAJYNPBKrz+IF998AP+tGIPAP/zxlbe3nyk18omhLC2fpve6c2gPz4nBYdNsXJXKY2BIKW1PrYdqSEU0jy5ci+bhldxwfhBvVY+IYR19c+g7w/16kImiW4HX8sfxEtri5qndjhU2UBpbSP+oOaLwkoCwVCPpZ+EEKJJv4w6jYFgp/vod7VvnTWMqgY/7249CsDhKi8HK82EbvW+IFsP1/Rm8YQQFtUvg74v2LvpHYDpw9MZPTARgEm5KRyp8jbP4gmwZr/07hFC9Lx+GfQb/aEe6aN/Ikop/t/5o5k9KpNLCnLwBUNsCg/YSo13smZ/Ra+WTwhhTVFFRqXUPKXUdqXULqXU3W0871ZKPR9+fpVSKi+8PUMp9YFSqlYp9duuLXr7GgOhHuujfyIXThjM0zdNJzfNjPJds7+CRLeD2aOyWLOvHK2lG6cQomd1GBmVUnbgd8CFwDjgGqXUuFa73QRUaK1PA34FLAlv9wL/DdzZZSWOgumy2bs5/UjZqSbobyyqIjs1jmnD0ymubmRzeNUtIYToKdFUh6cBu7TWe7TWPuA54JJW+1wCPBW+/xIwRymltNZ1WuuVmODfYxoDwV5P70RqmrXTFwyRneph/qRskuIc/Ob9nb1cMiGE1UQTGXOAAxGPi8Lb2txHax0AqoCMrijgyYiV9E6T9ARXc8NydqqHFI+TG2cN563NxWw+JBOzCSF6TkxERqXUzUqpNUqpNSUlJaf8fo2BEG5n7KR3zOydprafE0713Hj2cJLcDv60Ym9vFk0IYTHRBP2DwJCIx7nhbW3uo5RyAClAWbSF0Fo/prWeqrWempWVFe3L2tXb0zC0pWnK5qbgn+JxMnf8QN7fdpRAeKUvIYTobtFExtXAKKXUcKWUC1gALGu1zzLghvD9K4D3dS92TTGDs2Is6KeaYN/UqAtmAZaqBj9fHJBpmIUQPaPDyBjO0d8OvAVsBV7QWm9WSi1WSs0P7/YEkKGU2gXcATR361RK7QMeBhYqpYra6PnT5Xp7Goa2ZIdr+jkRQX/26EwcNsXFdLJ8AAAb3ElEQVR74VG7QgjR3aKae0dr/Trweqtt90bc9wJXtvPavFMo30mJhWkYWps7biBFFfUtavrJcU7OzEvn/W3F3H3hmF4snRDCKmKrOtwF9Bs/4DHbAzGX3pk0JJVHFkzGblMtts8ZO4AdxbUUltX3UsmEEFYSW5GxC4RKdjLFtgO3Q3W8cwyYl2+mWH7li9Zt40II0fX6XdDX/nqSVQNJura3ixKV3LR4Zo7M4O/rimRaBiFEt+t/Qd9nZrJM9x/u5ZJE74ozciksr2f1PpmETQjRvfpd0MdvcuNpja3SJaufgCcvhBisTc/LH0SCy87zqw90vLMQQpyCfhj0TU0/1dsq6G9bDoWfQGnszXcT73JwxRm5/GP9QQ6U17P+QCWf7o56bJsQQkSt3y2XqMI1/aSGomMbtYbDX5r7e/8FWaN7oWQndutXT+PZzw9w54tfsv5AJY2BEJdNziE/J4WCoalMGZrG31YV8rfP95OZ6OaHF41l9MCk3i62EKKP6Xc1fRUwNf2E+oiafvUhqC819/d+1Aul6tiglDiumTaEVXvLyU3z8B9fGcE/vjzE4te2cPUfP+XJlXv5739swhcI8cmuMp79vLC3iyyE6IP6V01fa2zhoB9fF5Efb6rlZ46GfSsgFAJb7J3vvjtnFEopbj5nBNmpHr43ZxSV9X6u+9MqFr+2hUHJcbx4y0xu/9s6Vu4s7e3iCiH6oNiLfKci0IhC06gduOsOQTBgth/+EpQNzroVGirg2QXw1DdM8I8hmYlufjJ/fPOo3XiXg+xUD08sPJNpeek8sqCAFI+T2aMy2Xm0lsNVDR28oxBCtNS/gn44n79L56B0EKrDef3DX0LGKBh9IaBg51smzVO6o/fK2gnDMxN44ZYZnDXCLFFw9mlmJlKp7QshOqt/pXfCQX+HzmU8++GFGyBxIBSthtPOh+TBsHA5BBrgr5fDwbUwoO/NeTNmUBKZiW6WfXmII1Ve1hVWsLe0jgZ/kAk5KVw7fSjnjRnY28UUQsSgflbTN+mOdaFRBJJyIBSAIxugoRxyzjD75M2CEeeBOxkOronufevK4LX/B/Xl3VTwzrHZFLNHZbJiZykPv7uDg5UN5OekMGtkJhsPVnHj0jWs3FmK1poar7+3iyuEiCH9sqZ/RKdT8p21ZuGSoB8KP4Xcacf2s9kgezIUdRD0fXXgSoAvnoY1T5r7F9zfjV8gend97XS+enoWs07LJDPR3bzd6w9y4a9X8MNXNjI+O5n3th7lpVtnMDE3tRdLK4SIFf2ypt+A+9jUynYnDD8HnHEt982dCsWbYdPL8JdLTbfOxlo48Ll5fus/4YFhcHAdbPq72fb5n6D21Jdz7ArZqR4uKchpEfAB4px2fv5v+RSW1/PW5iO4nTZ+9MomgqFjI5G9/iAfbj9KKBR7o5OFEN2rf9X0fXUA1Gt3x1Mr50wFHYS/f8f8+9R882/5Hrj6r/DhEgj54dXboGQrnPkdU9t/fzFc/OuY7PLZZObITH519SRy0+I5XOVl0bNf8LPXtvDtWXnsL6vnZ69tYefRWn69oIBLClqvcS+E6M/6V9AP1/S9uKII+uEcvzsRLnwQ/vk9iE+HjNPg5f8Afx0MnWmmbkDB7DvB7oLPfg9VB+HyP5n9Y9S/Tc4FQGvNv7aXsPSTfSz9ZB8AA5LcDEqO45nPCtsM+qGQJhDSMbf6mBDi1PXLoN+o3DjsHQSspIEwcxGMPBdGngfDZoInFYq3wJMXQMoQ+OaL8OgsSMszPX++9gvIHAVv3A1Pfg2u+zukDu3+73UKlFL88qpJ3HbuSFbuLGVoRjxTh6Xx7OeF/OL1bewormkxnYPWmu8+9wVr9pXz9E3TZaoHIfoZFWtzuE+dOlWvWRNlr5rW1j4F/1zEV4O/58OfffPkC/HlcybQDz0L6krBZgdP2rHn930Mz15jts97wAz4crhg6o0n/5k9rLzOx1m/eI8h6R4GJMVx17zTmTI0jRfXHOCulzbgdtiId9n5n8sm8rXxA1GqbyxKI4RVKaXWaq2ndrRfP6vpm947QYengx07MGnBsfsJmcc/nzcL/v090x7wys3HtjviYNTXTBfRzFGnVoZulp7g4j++MoJ3thSzu6SW65/4nKvPHMKznxcybXg6Sy6fyHeeWs0tf11LTqqHEVkJBIKa1HgnP5k/noHJcXj9QYoq6slNiyfOGVtrEgsh2ta/avorfgnvLWaW4zk+/vGFXVuwtgT9sOMtyBgJr98FhZ+Z7SG/6SI6739ML6EYd7iqgQWPfUZheT3nnj6An/9bPoNTPASCIZZ9eYh3txZzsKIBl8PG5kPVJLrN9BAbiioJabhowiB+/80zevtrCGFpFq3pNxDChs3p6pnPszth7MXm/pVL4eWbIWsMJGfDZ3+AP18IX38YJl8HMZweGZziYdntZ1PvC5ixDWEOu43LpuRy2ZTc5m1bD1dz10tmArvbvnoaR6q9vLS2iNX7yjkz7+Qbtmu8fqq9AXJST/EqTQhxQv0u6PuUG7ezF75WQiZ86+VjjwuuhReuh2W3w9o/mxNBoBHO/RFkF/R8+TqQ4nGS4nF2uN/Ywcm89t3ZzY8bfEFW7Czh/uVbeemWGTgjGtC3HKrmwbe24fWHmDw0lUVzRjWngWq8fn76zy1sKKokPyeFd7cU4wuGeOW2WYwdnIzWWtoRhOgG/Svo++rwqjgS3THwteLT4VuvwpfPmrRTQyU0VsPj55nuou4kQEP2FDP7Z0KmWeylrgQSsmL6yiCSx2XnngvH8l/Pr2fBY59xxrA0viisYOzgZF5ZdxC300ZuWjy//3A3b246QnqCixpvgLK6Rirq/UwdlsY7m4uZPiKDDUWVzW0Iq/aWk5noYubITK6aOoSzRqQ3nwR2FteQGu8iK8ndQemEEK3FQHTsQv4GGrSLAbESDOwOmPItcwPTy+df/2tGAjdUgA6ZE8InvzETwlXuh+JNMO4SkxZqqxE5Bl06OQe7TXH33zewoaiSMYOSee7zA4zISuDP3z6TwSkePth+lEfe2YHDrsjLjOe0gYl8e2YeUyNSQqv3lXPNY59R7wuycGYeZbWNvLulmFe+OMiwjHjOGzOAusYAL64tIjvFw4u3zKC2MYDLbiMvM4G6RjOVttth44E3tlFU0cAPLhzD8MyE48rc+kpCa01lvZ+0hB5KDQrRS/pXQ+7z32LX1i9YWvAs9186oWsL1l1KdsCaJ2DraxCXAnlnm3SQI870Itr5DgS8MP0WM1WEt8qcIHKnQuowMzJYazO5nL3j9Ex3qmrwg4aUeCdefxC3w9bpFE1RRT2Zie7mNFCDL8gbmw7z0toi1hVW4AuEuGrqEJZvOExIa+p8QQAm5aaw9XANNhvkZSSw7UgNcU4boRB8feJgkuIcvLLuILnp8QxIcvPpnjJGZiVy7bQhfHP6MO5btpnnVhfylxunM2NkRpcfGyG6W7QNuf0q6IeevpwNO/fw0VdeYNGc2O4yeUJHt8F7i2H7cjNdhN1lRgY74sykb/XhRdM96TB6HhxeD0e3mGmkT78QRs6B7a+bK4X8K8woY3didJ+tdcymloIhTb0vQFKck9X7yvnl29s5f+xAahsDvLu1mKnD0vH6g7y7tZg75p7O+eMG8Lv3d/HyFwfx+oPMyx9McbWX0tpGzhqRwaaDVWwoqmJibgobiqrwOO3EOW08smAyIzITGJQS19xGsa+0DptS5KR5+Mun+3DYbVw3fai0O4iYYcmg3/j4PNYVVrHvG89zzbTYHikbFW91OPcPlO2C5BwT+A+vN2mgPf+CHW9C1ukw4lyTHtqyDIKN5qrBV2euAADcKZCYZR4n58CIr5qbOxkq9pr32PkOfPg/ZsBZ5FiFPs7rD9IYCB3XUK215smP9/Hz5VuYPjyDn12azxWPfkJlvZmO2qZgzKBkslM9vLetGICcVA9FFWbk942zhjMg2c3Hu0pZt78CXzBEXkYC3583hqnD0ghqTVmtjz0ltRyu8qKUaQifOiytzRHjWmvK6nykeJwtGsQBPttTRmW9n3n5g7rjEIl+wJJBv/63s/ms2Ia+9gXmjLXoIiI1xXB0MwybBY01sPsDs4JY9SHTSKzs5gRy+Eugjb99XIrpZTT7/4N1fzFTUwyaZK4a4jMgaZAZeJY52lx1BHwmrdSHa7x7SmrJTvUQ57RTXudjy6FqDlU2cKCinlV7y9l1tJarpg7BZVd8tLOUhTPzWLW3vHlx+lEDEpk+Ip1Et5N3thxhd0ndCT/P7bCRGu8kOc5JssdJcpyDygY/u4/WUu0NMCwjnkevO4NgSFNYXs+6/RX8aeVeAL5z9nBu+erI42ZXFcKSQb/24TP4V0U6Q/7jRZk/viP15WbJSH8DpA+HIxtNUM87G/54DtQcNgPMXPFQst2klIK+lu/hToHGKvO6gfnmeXeymcLCnWQGreWcYVYuCzTC0BlmHIPNBqGguVoJBc3aBn3spKG1Zv2BSnJSPQxIPjZttz8Y4s1NRyirbUQpRXqCi7yMBHLSPIS0ZvXectbur6Da66fGG6Da66eqwU+S28nIAQnkpMbz5Md7KalpbPF5C84cgtth46lP9wOQkeBi9MAkvnJ6Fg6bYukn+8hMdDNnzAAunZzDgYp6Pt9bji8Qwh8M4Q9q/MEQg1PiGJIezxeFlWSnxnHDzDzsSrGusJI1+8vJTvEwIMmNP6SZlpeOx2XHHwzhsKk2U1laaxoDIRmRHQOsGfSXjOWt2pHMuvMlBqXEdfwC0baSHWb94DFfPxaMtQZfrbliKNkOpdvNVUVCJlQWmm1Oj+maWrnf7KvbWHjekwYJA8xrAuGF3bPGmNcGGiFtuJnhtPoQVB82J6QRX4EB4yDzdHPlUfiZmerC5jRXGekjzAml+qBJaaXknngG1BhutwAorvbyzKpCRmQmcPqgJFLjnc2D5lbvK2dDURU7jtSw6VAVmw9VAzAtLx1fMMSXRZVE/pd22BQOu8Jpt+GwKSrCqSu3w0ZjIERWkptab4AGf/C4cgxIcjMuO5kVO0sZn51MwZBUVu4qJTnOScGQVM4akcEzq/azak85t3xlBLNHZ9HgCzI+O5kEt4OSmkaO1ngJBDX+oOajnSUkuR18++zhLbpVH6xsYMuhahr8Qbz+IMlxDr4yegAel5xIOsOSQb/u58N5xTuZq3/y0nE5UdHDtDYppENfmJ5GrgTY/6lpkG6oNLOTZk8xJ4dNfzeN1XYnVOwDV6IZzJY0yHRvPfC5mdrihBQt0lWDJ0HGKNNeUb4HggHTblF9yFy1pA+HuFTzmXaXucUlw6AJUHnArKGQPQXShpnpNir2m5NUXKo5waTlmZ5UNjuU7oTd75kTTkKW6V3lSjCvc7jg8AaoOmBOTk0nnDEXQ9Jg8Faaqx1vpXm/hEyz3RndyOTCsnqqvX7yc1IA0/vpjY1HGJQSx/ljBx4XOKvq/RSW1zN6UCKf7i7jr58VMiTdw5l56cwYkUFxjZfKej/1vgCP/msPBysaOHdMFp/sLqOovIEZIzPw+oN8WVSJ1x8i0e3gzLw0Ptje8eJCTrvCH9SkJ7gYn52M22GnuNrLxoNVx+0b77IzMDkOXyBERb2P7FQP47OTsStFSGtCGgKhEEPS4pmal44vEGLDwUo2HKgiM8lNqseJUpCb5mHMoGQmD01FKcWbm440zy915Rm57Dpay8gBiYzMSqTa6w/3OrOTHOdAa2jwB0lwO9Ba0+APEu+K3V7ulgz6jYsH8YI+n2/d99cuLpXoVUG/ORmU7jCznuaeaWrzoYBJKR1aD0Wfm6uEuGTTZrH9DXMlkj7cpJmUzVyNJGebwFyxz7R5BP2m4TvoM2sh1xwChwcyTzO9qJpONg6PCeTeymON45ESBoSveg6Ar+b4512J5gTXTJng39bVEJg0mc1uPteTZm52p+m+6683r3Mlmm67rgQo2WYep+SY1zhcYHeb11QdMGtApOWZKyCbwzTm65C5OqoqMu9pc5qxJe4USB1iUnSOOHC40fXlhLzV2N2J4E7C5/dzeN82Mj2KhIREDtcrarQb7U5hR5WdBlsCicnppCUn4NaNOLxljEpspLiyjtd2NrCpIZ2joWTS4uzMGJ7CtNMGE5+UQpwtxIHyWt7cWkFFvR+HTZHqcXKopJTdJbV4bR5sSqEwa0UfKK/HHzQxzGlXjBucTEW9nxqvn2BIU+09/m81ND2ewvL6FttSPE7T5Tgs0e3AFwjhC5qrIa8/SI03wLTh6UwdlobTbjOpuXozfYjHZSfR7cDtsLHlUDXFNV5SPU5GZCUyMiuBZI+TpDhz9bN84xE8ThunDTA96oIhjdth5/yxA5kxMgO77eSuQq0X9LUm9NM0nnVfxTfveazrCyasobbEdG91ekx7h7fKNH4nZJog7feaq5W6MpNqCgXNSSR7smmrCPjg0DpTo7c5TDDNHG2uWpqm6fZWmaubQKN5rc1mAm1cCtSXHmt0DwXN1UVDpRnMF/SZIOz0mJNYY625kmmshQFjwFdvTloB37ETGZirk5QhJu3WWH38d04caE4YIb+5ImqoOJZ660mOOHNSA3NSQpkTs6/m2MkxZahZ4a62GOxuQvEZNDjTcHlLsNvt2JIGmeNhs0PiQPxaUdvQSI3XT8juJskRIj1YSo0nhyJbNpnuIDVVFdQ1eHHGp6DdSTQQR403gN2uiHPYqKz3Y7cp3E4HX5aEOFQHIQ1uh504lx23w44/ZK4KvAFISU0jKTmNEp+TkvJKqusbKNMpNIbHwp4+MAmU4mBFA/E2PwnKR6PPR2kgjjGjRvHwjRec1OGz3oRrgUZsaBxxx4++FCJqiVnH7js9x6dZnHFm0Z32OFxmHYYTvXd8Opxz56mVMxqhUPhE4W7ZhhHwmR5dKHPl42jVE0hrkwLz1ZoTU6DRXGm4E82JsLEW0OYqw+E2n+FvMPt7qyJu1eZE4ogzJ82ELHMCrS8zKbeGcnNitDlMsK89Gu6irMzJTNnM46ZbKGAWObI7zUk04MNWV0JCfSnkjDMnydoj5rlQEGqO4ESTZrORFq8gWGc+P304yWW7GFf1CbgSGOBKAIcDamqhtLp5iva2zIKWUdMfvjWxAdXhW5PWg7wrI/9G4X/t5naUC4GTC/rRiiroK6XmAb82xeJPWusHWj3vBv4CnAGUAVdrrfeFn7sHuAkIAou01m91Wekjhf9QrrgoByEJ0d/ZbGBro0ODw2XaF9qjVDhItzENSORiQs3v5zY3T6pJu0Ujb1Z0+/WG9hr6Q0FzMgv6zD7oNv4Nmbadxhpzc3rMSa2utGXvt6Yrl6YrN5sdvNUMSMg6/nO7WIdBXyllB34HzAWKgNVKqWVa6y0Ru90EVGitT1NKLQCWAFcrpcYBC4DxQDbwrlJqtNb6+K4Cp0j76lBAXIIs7yeEOAXt9eyy2WN6XexoRdPFZRqwS2u9R2vtA54DLmm1zyXAU+H7LwFzlOnUewnwnNa6UWu9F9gVfr8uV11jGs888VLTF0KI9kQT9HOAAxGPi8Lb2txHax0AqoCMKF/bJSqqTLevhESp6QshRHtiojO7UupmpdQapdSakpKO+/u2xeZOYF3iV0jPPkGuUgghLC6ahtyDwJCIx7nhbW3tU6SUcgApmAbdaF6L1vox4DEwXTajLXykoaMmMvTOZSfzUiGEsIxoavqrgVFKqeFKKRemYbZ1dF0G3BC+fwXwvjYDAJYBC5RSbqXUcGAU8HnXFF0IIURndVjT11oHlFK3A29humw+qbXerJRaDKzRWi8DngCeVkrtAsoxJwbC+70AbAECwH92R88dIYQQ0ek/I3KFEMLCoh2RGxMNuUIIIXqGBH0hhLAQCfpCCGEhEvSFEMJCJOgLIYSFxFzvHaVUCbD/FN4iEyjtouJ0JSlX50i5Oi9Wyybl6pyTLdcwrXWH03TGXNA/VUqpNdF0W+ppUq7OkXJ1XqyWTcrVOd1dLknvCCGEhUjQF0IIC+mPQT9WF8iVcnWOlKvzYrVsUq7O6dZy9bucvhBCiPb1x5q+EEKIdvSboK+UmqeU2q6U2qWUursXyzFEKfWBUmqLUmqzUup74e0/UUodVEqtD98u6qXy7VNKbQyXYU14W7pS6h2l1M7wv22sft2tZTo94risV0pVK6X+qzeOmVLqSaXUUaXUpohtbR4fZfxf+De3QSk1pYfL9aBSalv4s19RSqWGt+cppRoijtuj3VWuE5St3b+dUuqe8DHbrpT6Wg+X6/mIMu1TSq0Pb++xY3aCGNEzvzOtdZ+/YaZ83g2MAFzAl8C4XirLYGBK+H4SsAMYB/wEuDMGjtU+ILPVtv8F7g7fvxtY0st/yyPAsN44ZsA5wBRgU0fHB7gIeANQwFnAqh4u1wWAI3x/SUS58iL366Vj1ubfLvx/4UvADQwP/7+191S5Wj3/S+Denj5mJ4gRPfI76y81/WgWb+8RWuvDWut14fs1wFa6aV3gLhS5sP1TwKW9WJY5wG6t9akM0DtpWuuPMGtCRGrv+FwC/EUbnwGpSqnBPVUurfXb2qxJDfAZZmW6HtfOMWvPJcBzWutGrfVeYBfm/2+PlksppYCrgGe747NP5AQxokd+Z/0l6PfYAuydoZTKAyYDq8Kbbg9fnj3Z0ymUCBp4Wym1Vil1c3jbQK314fD9I8DA3ikaYBbgifyPGAvHrL3jE0u/uxsxtcEmw5VSXyil/qWUmt1LZWrrbxcrx2w2UKy13hmxrcePWasY0SO/s/4S9GOOUioR+DvwX1rrauAPwEigADiMubTsDWdrracAFwL/qZQ6J/JJba4ne6VLlzLLcc4HXgxvipVj1qw3j097lFI/wqxM90x402FgqNZ6MnAH8DelVHIPFyvm/natXEPLykWPH7M2YkSz7vyd9ZegH9UC7D1FKeXE/DGf0Vq/DKC1LtZaB7XWIeBxuumStiNa64Phf48Cr4TLUdx0uRj+92hvlA1zIlqntS4OlzEmjhntH59e/90ppRYCFwPfDAcKwqmTsvD9tZi8+eieLNcJ/naxcMwcwGXA803bevqYtRUj6KHfWX8J+tEs3t4jwrnCJ4CtWuuHI7ZH5uD+DdjU+rU9ULYEpVRS031MQ+AmWi5sfwPwj54uW1iL2lcsHLOw9o7PMuD6cO+Ks4CqiMvzbqeUmgd8H5ivta6P2J6llLKH748ARgF7eqpc4c9t72+3DFiglHIrpYaHy/Z5T5YNOB/YprUuatrQk8esvRhBT/3OeqK1uidumBbuHZgz9I96sRxnYy7LNgDrw7eLgKeBjeHty4DBvVC2EZieE18Cm5uOE5ABvAfsBN4F0nuhbAlAGZASsa3HjxnmpHMY8GNypze1d3wwvSl+F/7NbQSm9nC5dmFyvU2/s0fD+14e/vuuB9YB3+iFY9bu3w74UfiYbQcu7MlyhbcvBW5ptW+PHbMTxIge+Z3JiFwhhLCQ/pLeEUIIEQUJ+kIIYSES9IUQwkIk6AshhIVI0BdCCAuRoC+EEBYiQV8IISxEgr4QQljI/w/n6x2xN+PJ/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Regression of old state and performed action to new state and observed reward.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "rtx = []\n",
    "rty = []\n",
    "stx = []\n",
    "sty = []\n",
    "plotr = []\n",
    "plots = []\n",
    "\n",
    "regressorReward = RandomForestRegressor(n_estimators=10, min_samples_split=2)\n",
    "regressorState = RandomForestRegressor(n_estimators=10, min_samples_split=2)\n",
    "\n",
    "old_state = env.reset()\n",
    "\n",
    "print(\"Regression...\")\n",
    "for i in range(epochs):\n",
    "    \n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "\n",
    "    rtx.append(np.append(old_state ,action))\n",
    "    rty.append(reward)\n",
    "    stx.append(np.append(old_state,action))\n",
    "    sty.append(next_state)\n",
    "    \n",
    "    if i%50==0: # 50 works nicely\n",
    "        \n",
    "        regressorReward.fit(rtx, rty)\n",
    "        fitrtx = regressorReward.predict(rtx)\n",
    "        mse = mean_squared_error(rty, fitrtx)\n",
    "        plotr.append(mse)\n",
    "\n",
    "        \n",
    "        regressorState.fit(stx, sty)\n",
    "        fitstx = regressorState.predict(stx)\n",
    "        mse = mean_squared_error(sty, fitstx)\n",
    "\n",
    "        plots.append(mse)\n",
    "    \n",
    "    old_state = np.copy(next_state)\n",
    "\n",
    "print(\"...done\")\n",
    "plt.figure(0)\n",
    "plt.plot(plotr, label=\"Loss for reward fitting\")\n",
    "\n",
    "plt.plot(plots, label=\"Loss for state fitting\")\n",
    "plt.legend()\n",
    "print(regressorReward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n   Value Iteration\\n   \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Value Iteration\n",
    "   \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy iteration...\n",
      "\n",
      "Evaluating policy\n",
      "Delta:  18.901789323805502\n",
      "Delta:  4.347388226676806\n",
      "\n",
      "Improving policy\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'discretization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7a356ce60f3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mvalue_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlarry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-7a356ce60f3d>\u001b[0m in \u001b[0;36mpolicy_iteration\u001b[0;34m(disc, theta, gamma)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstable_policy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mpolicy_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mstable_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_improvement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7a356ce60f3d>\u001b[0m in \u001b[0;36mpolicy_improvement\u001b[0;34m(gamma)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Improving policy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mpolicy_stable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0ms0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscretization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_space_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscretization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_space_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscretization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_space_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'discretization' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Policy Iteration\n",
    "    \n",
    "    Gives convergence towards the optimal policy by iteratively\n",
    "    performing Policy Evaluation and Policy Improvement\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def policy_iteration(disc, theta, gamma):        \n",
    "    \n",
    "    print(\"Policy iteration...\")\n",
    "\n",
    "    value_function = np.ones(shape=disc.state_space_size)\n",
    "    policy = np.ones(shape=disc.state_space_size)\n",
    "\n",
    "    \n",
    "    def policy_evaluation(theta, gamma):\n",
    "        print()\n",
    "        print(\"Evaluating policy\")\n",
    "        delta = theta\n",
    "        while delta >= theta:\n",
    "            delta = 0\n",
    "            # Iteratate over discrete state space\n",
    "            for s0 in disc.state_space[0]:\n",
    "                for s1 in disc.state_space[1]:\n",
    "                    for s2 in disc.state_space[2]:\n",
    "                        \n",
    "                        index = disc.map_to_index([s0, s1, s2])\n",
    "                        \n",
    "                        v = value_function[index[0], index[1], index[2]]\n",
    "                        \n",
    "                        \"\"\"\n",
    "                         V(s) = Sum...p(s',r|s,pi(s))[r+gamma*V(s')]\n",
    "                         \n",
    "                        \"\"\"\n",
    "                        a = policy[index[0], index[1], index[2]]\n",
    "                        \n",
    "                        # input for regression\n",
    "                        x = np.array([s0, s1, s2, a]).reshape(1, -1)\n",
    "                        \n",
    "                        # Predict next state and reward with regressors\n",
    "                        next_s = regressorState.predict(x).T\n",
    "                        r = regressorReward.predict(x)\n",
    "                        \n",
    "                        \n",
    "                        next_index = disc.map_to_index([next_s[0], next_s[1], next_s[2]])\n",
    "                                                     \n",
    "                        \n",
    "                        value_function[index[0], index[1], index[2]] = r + gamma*value_function[next_index[0],\n",
    "                                                                              next_index[1], next_index[2]]\n",
    "                        \n",
    "                        \n",
    "                        delta = max(delta, v - value_function[index[0], index[1], index[2]])\n",
    "            print(\"Delta: \", delta)\n",
    "    \n",
    "    \n",
    "    def policy_improvement(gamma):\n",
    "        print()\n",
    "        print(\"Improving policy\")\n",
    "        policy_stable = True\n",
    "        for s0 in range(discretization.state_space_size[0]):\n",
    "                for s1 in range(discretization.state_space_size[1]):\n",
    "                    for s2 in range(discretization.state_space_size[2]):\n",
    "                        old_action = policy[s0, s1, s2]\n",
    "                        \n",
    "                        \"\"\"\n",
    "                            pi(s) = argmax_a ... \n",
    "                            We do not have to care about the prob. distribution,\n",
    "                            as we have a deterministic env.\n",
    "                            \n",
    "                        \"\"\"\n",
    "                        # Iterate over all actions and get the one with max. expected reward\n",
    "                        amax = 2\n",
    "                        rmax = -100\n",
    "                        for a in discretization.action_space:\n",
    "                            x = np.array([s0, s1, s2, a])\n",
    "                            x = x.reshape(1,-1)\n",
    "                            next_s = regressorState.predict(x).T\n",
    "                            next_s = discretization.disc(\"state\", next_s)\n",
    "                            r = regressorReward.predict(x)\n",
    "                            expected_reward = r + gamma*value_function[next_s[0], next_s[1], next_s[2]]\n",
    "                            if rmax < expected_reward:\n",
    "                                amax = a\n",
    "                                rmax = expected_reward \n",
    "                        policy[s0, s1, s2] = amax # TODO\n",
    "                        \n",
    "                        if old_action != policy[s0, s1, s2]:\n",
    "                            policy_stable = False\n",
    "                            \n",
    "        print(\"Policy stable: \", policy_stable)\n",
    "        return policy_stable\n",
    "        \n",
    "    # Run until policy is stable\n",
    "    stable_policy = False\n",
    "    while not stable_policy:\n",
    "        policy_evaluation(theta, gamma)\n",
    "        stable_policy = policy_improvement(gamma)\n",
    "    \n",
    "    print()\n",
    "    print(\"...done\")\n",
    "    return value_function, policy\n",
    "    \n",
    "value_function, policy = policy_iteration(larry, theta=5, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Some stuff to see the predictions, discretizations and learned functions in action\n",
    "\n",
    "\"\"\"\n",
    "rewards_per_episode = []\n",
    "\n",
    "for e in range(5):\n",
    "    \n",
    "    # Discretize first state\n",
    "    state = larry.disc(\"state\",env.reset())\n",
    "    \n",
    "    rewards_per_timestep = []\n",
    "    \n",
    "    for t in range(1000):\n",
    "        # Render environment\n",
    "        # env.render()\n",
    "\n",
    "        # Do step according to policy and get observation and reward\n",
    "        action = np.array([policy[state[0], state[1], state[2]]])\n",
    "        print(action)\n",
    "        #action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "        rewards_per_timestep.append(reward)\n",
    "        \n",
    "        # Discretize observed state\n",
    "        state = larry.disc(\"state\", observation)\n",
    "\n",
    "        if done:\n",
    "            print(\"Episode {} finished after {} timesteps\".format(e+1, t+1))\n",
    "            break\n",
    "    \n",
    "    rewards_per_episode.append(rewards_per_timestep)\n",
    "\n",
    "# Average reward over episodes\n",
    "rewards = np.average(rewards_per_episode, axis=0)\n",
    "print(np.shape(rewards))\n",
    "        \n",
    "env.close()\n",
    "\n",
    "# Plot rewards per timestep averaged over episodes\n",
    "plt.figure()\n",
    "plt.plot(rewards, label='Average reward per timestep')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
